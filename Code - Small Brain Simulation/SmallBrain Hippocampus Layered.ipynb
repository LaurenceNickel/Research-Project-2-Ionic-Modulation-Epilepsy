{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fc590d-d3fa-4c9c-9091-ce65833ce1ca",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 50px;\">Research Project 2 Epilepsy Ionic Modulation - SmallBrain Hippocampus Regions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d45db-ecde-4107-817b-22d1d7d4bbd5",
   "metadata": {},
   "source": [
    "PLACEHOLDER FOR SMALL EXPLANATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc7291-82c6-44cd-bf20-c4b008e74319",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad949241-52a7-44c4-aa78-34ef69aac4a8",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Installing and Importing Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f62ff77-02e0-403a-92d7-862c41466727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:40:58.003345Z",
     "start_time": "2024-06-19T09:35:28.326945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installing all the required libraries.\n",
    "!pip install -q jupyter\n",
    "!pip install -q matplotlib\n",
    "!pip install -q numpy\n",
    "!pip install -q pandas\n",
    "!pip install -q plotly\n",
    "!pip install -q scipy\n",
    "!pip install -q tqdm\n",
    "!pip install -q Brian2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1719df-92c4-40dc-955a-014a5520b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries.\n",
    "from plots import *\n",
    "from equations import *\n",
    "from global_settings import *\n",
    "from masks import *\n",
    "from helper import *\n",
    "from run_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4571ab25-9c49-4338-b976-6d70d9f232e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from brian2 import *\n",
    "import random\n",
    "from itertools import chain, zip_longest\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a64da5-9001-4f34-88e0-65ab7a52d6d5",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b8eac-14cb-41f7-9f52-43ec07831c66",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">General Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cc288b-240a-44cd-b832-2981ae76846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the stimulus input signal.\n",
    "def read_input_signal(file_name):\n",
    "    in_1 = np.loadtxt('./stimuli/'+file_name)\n",
    "\n",
    "    # Converting the signal to be of type 'TimedArray' with a specified time step which can be used in the simulation.\n",
    "    input_signal = TimedArray(in_1*namp,dt=defaultclock.dt)\n",
    "\n",
    "    return input_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc359126-3c97-46d7-b487-0f9038849406",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5655bd2-c00e-4dcd-9d6e-4a624facd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the mask with the provided coordinate center and radius can be applied to the list of regions.\n",
    "def checking_mask(shape_mask, list_of_regions, center_coordinates, radius_or_edge_length, region_names, region_geometrics):\n",
    "\n",
    "    # Checking if the 'list_of_regions' is empty.\n",
    "    if len(list_of_regions) == 0:\n",
    "        raise ValueError(\"The 'list_of_regions' list is empty.\")\n",
    "    \n",
    "    # Checking if the 'list_of_regions' only contains valid region names.\n",
    "    if not all(region in region_names for region in list_of_regions):\n",
    "        raise ValueError(\"The 'list_of_regions' list contains an invalid region name.\")\n",
    "    \n",
    "    # Checking if there are no duplicate region in the 'list_of_regions'.\n",
    "    if len(list_of_regions) != len(set(list_of_regions)):\n",
    "        raise ValueError(\"The 'list_of_regions' list contains duplicate regions.\")\n",
    "\n",
    "    # Checking that the 'list_of_regions' list only contains regions that are adjacent to each other (otherwise the stimulus mask would pass through regions that are not in this list).\n",
    "    if len(list_of_regions) > 1:\n",
    "        region_indices = [region_names.index(region) for region in list_of_regions]\n",
    "        if not all(region_indices[i] + 1 == region_indices[i+1] for i in range(len(region_indices) - 1)):\n",
    "            raise ValueError(\"The 'list_of_regions' list contains regions that are not adjacent to each other.\")\n",
    "\n",
    "    # Checking if the coordinates of the center of the mask are positive.\n",
    "    if not (center_coordinates[0] > 0 and center_coordinates[1] > 0 and center_coordinates[2] > 0):\n",
    "        raise ValueError(\"The coordinates of the center of the mask should be positive.\")\n",
    "\n",
    "    # Checking if the radius of the mask is positive.\n",
    "    if not (radius_or_edge_length > 0):\n",
    "        raise ValueError(\"The radius of the mask should be positive.\")\n",
    "\n",
    "    # Generating 'num_edge_points' random points that are located on the edge of the mask which is either spherical, cubical, or all.\n",
    "    num_edge_points = 10000\n",
    "    if shape_mask == \"spherical\":\n",
    "        radius = radius_or_edge_length\n",
    "        edge_points = generating_n_random_points_spherical_edge(num_edge_points, center_coordinates, radius)\n",
    "        \n",
    "    elif shape_mask == \"cubical\":\n",
    "        edge_length = radius_or_edge_length\n",
    "        edge_points = generating_n_random_points_cubical_edge(num_edge_points, center_coordinates, edge_length)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"The shape of the mask given is not valid. Please select either 'spherical' or 'cubical'.\")\n",
    "\n",
    "    # Checking whether every point present in the 'edge_points' is located within the list of regions.\n",
    "    for edge_point in edge_points:\n",
    "        point_in_region = False\n",
    "        for region in list_of_regions:\n",
    "            match region:\n",
    "                case \"DG_CA3\":\n",
    "                    point_in_region = check_point_within_DG_CA3_region(edge_point, region_geometrics)\n",
    "                case \"CA1\":\n",
    "                    point_in_region = check_point_within_CA1_region(edge_point, region_geometrics)\n",
    "                case \"Sub\":\n",
    "                    point_in_region = check_point_within_Sub_region(edge_point, region_geometrics)\n",
    "                case \"EC\":\n",
    "                    point_in_region = check_point_within_EC_region(edge_point, region_geometrics)\n",
    "            if point_in_region:\n",
    "                break\n",
    "        if not point_in_region:\n",
    "            raise ValueError(\"Not every point present in the mask will be within the defined regions.\")\n",
    "\n",
    "    return [center_coordinates, radius_or_edge_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed147088-bcdb-47c8-aaba-0ffa33729c5d",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d6a1a8-017a-4b61-84c2-99a35a92eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the treatment mask with the provided coordinate center and radius can be applied to the list of regions.\n",
    "def checking_treatment_mask(shape_mask, list_of_regions, center_coordinates, radius_or_edge_length, region_names, distance_between_masks, stimulus_coordinates, region_geometrics):\n",
    "\n",
    "    # Retrieving the x-coordinate, y-coordinate, and z-coordinate from the 'center_coordinates' parameter.\n",
    "    treatment_x, treatment_y, treatment_z = center_coordinates\n",
    "\n",
    "    # Retrieving the x-coordinate, y-coordinate, and z-coordinate from the 'stimulus_coordinates' parameter.\n",
    "    stimulus_x, stimulus_y, stimulus_z = stimulus_coordinates\n",
    "    \n",
    "    # Checking whether the distance between the masks is at least equal to 'distance_between_masks'.\n",
    "    distance_xyz = np.sqrt((treatment_x - stimulus_x)**2 + ((treatment_y - stimulus_y)**2) + ((treatment_z - stimulus_z)**2))\n",
    "    if distance_xyz <= distance_between_masks:\n",
    "        raise ValueError(\"The distance between the masks is smaller than required.\")\n",
    "    \n",
    "    # Checking whether the treatment mask with the provided coordinate center and radius can be applied to the list of regions.\n",
    "    center_coordinates, radius_or_edge_length = checking_mask(shape_mask, list_of_regions, center_coordinates, radius_or_edge_length, region_names, region_geometrics)\n",
    "\n",
    "    return [center_coordinates, radius_or_edge_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5736d5-ccaf-4d13-9ca8-5a1794b668d4",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d45825d-afcf-4577-a569-b6cfa46c59d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating n random points that are located on the edge of the spherical mask.\n",
    "def generating_n_random_points_spherical_edge(num_points, center_coordinates, radius):\n",
    "\n",
    "    # Looping 'num_points' times and for each loop generating a random point on the edge of the spherical mask.\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        # Generating the components needed to generate a point on the edge exactly 'radius' away from the center coordinates.\n",
    "        phi = np.random.uniform(0, 2 * np.pi)\n",
    "        costheta = np.random.uniform(-1, 1)\n",
    "        theta = np.arccos(costheta)\n",
    "\n",
    "        # Generating a random point that is located on the edge of the spherical mask.\n",
    "        x = center_coordinates[0] + radius * np.sin(theta) * np.cos(phi)\n",
    "        y = center_coordinates[1] + radius * np.sin(theta) * np.sin(phi)\n",
    "        z = center_coordinates[2] + radius * np.cos(theta)\n",
    "\n",
    "        # Appending the randomly generated point to the 'points' array.\n",
    "        points.append([x, y, z])\n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c9cf37-8a9d-47fb-aba2-0e6ea3a09183",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38edcf89-9b3b-4d04-80d1-a385d112fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating n random points that are located on the edge of the cubical mask.\n",
    "def generating_n_random_points_cubical_edge(num_points, center_coordinates, edge_length):\n",
    "\n",
    "    # Looping 'num_points' times and for each loop generating a random point on the edge of the cubical mask.\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        \n",
    "        # Generating a random face of the cube on which the random point will be located.\n",
    "        face = np.random.randint(0, 6)  \n",
    "\n",
    "        # Depending on the face generated, a random point will be created.\n",
    "        match face:\n",
    "        \n",
    "            # The right hand side face.\n",
    "            case 0: \n",
    "                x = center_coordinates[0] - edge_length/2\n",
    "                y = np.random.uniform(center_coordinates[1] - edge_length/2, center_coordinates[1] + edge_length/2)\n",
    "                z = np.random.uniform(center_coordinates[2] - edge_length/2, center_coordinates[2] + edge_length/2)\n",
    "\n",
    "            # The left hand side face.\n",
    "            case 1:\n",
    "                x = center_coordinates[0] + edge_length/2\n",
    "                y = np.random.uniform(center_coordinates[1] - edge_length/2, center_coordinates[1] + edge_length/2)\n",
    "                z = np.random.uniform(center_coordinates[2] - edge_length/2, center_coordinates[2] + edge_length/2)\n",
    "\n",
    "            # The bottom face.\n",
    "            case 2:\n",
    "                x = np.random.uniform(center_coordinates[0] - edge_length/2, center_coordinates[0] + edge_length/2)\n",
    "                y = center_coordinates[1] - edge_length/2\n",
    "                z = np.random.uniform(center_coordinates[2] - edge_length/2, center_coordinates[2] + edge_length/2)\n",
    "\n",
    "            # The top face.\n",
    "            case 3:\n",
    "                x = np.random.uniform(center_coordinates[0] - edge_length/2, center_coordinates[0] + edge_length/2)\n",
    "                y = center_coordinates[1] + edge_length/2\n",
    "                z = np.random.uniform(center_coordinates[2] - edge_length/2, center_coordinates[2] + edge_length/2)\n",
    "\n",
    "            # The front face.\n",
    "            case 4:\n",
    "                x = np.random.uniform(center_coordinates[0] - edge_length/2, center_coordinates[0] + edge_length/2)\n",
    "                y = np.random.uniform(center_coordinates[1] - edge_length/2, center_coordinates[1] + edge_length/2)\n",
    "                z = center_coordinates[2] - edge_length/2\n",
    "\n",
    "            # The rear face.\n",
    "            case 5:\n",
    "                x = np.random.uniform(center_coordinates[0] - edge_length/2, center_coordinates[0] + edge_length/2)\n",
    "                y = np.random.uniform(center_coordinates[1] - edge_length/2, center_coordinates[1] + edge_length/2)\n",
    "                z = center_coordinates[2] + edge_length/2\n",
    "\n",
    "        # Appending the randomly generated point to the 'points' array.\n",
    "        points.append([x, y, z])\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe1ca8-0182-4a6a-bec1-b6ffbbeff886",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39940278-ed1c-44cf-93f6-60022745ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the point is located within the DG_CA3 region.\n",
    "def check_point_within_DG_CA3_region(point, region_geometrics):\n",
    "\n",
    "    # Retrieving the x-coordinate, y-coordinate, and z-coordinate from the 'point' parameter.\n",
    "    x_point, y_point, z_point = point\n",
    "\n",
    "    # Retrieving the bottom left x-coordinate, y-coordinate, and z-coordinate of the DG_CA3 region from the 'region_geometrics' parameter.\n",
    "    DG_CA3_bottom_left_x, DG_CA3_bottom_left_y, DG_CA3_bottom_left_z  = region_geometrics['DG_CA3_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the DG_CA3 region from the 'region_geometrics' parameter.\n",
    "    DG_CA3_width = region_geometrics['DG_CA3_block']['width']\n",
    "    DG_CA3_height = region_geometrics['DG_CA3_block']['height']\n",
    "    DG_CA3_depth = region_geometrics['DG_CA3_block']['depth']\n",
    "\n",
    "    # Checking whether the point is located within the DG_CA3 region.\n",
    "    if ((x_point >= DG_CA3_bottom_left_x and x_point <= DG_CA3_bottom_left_x + DG_CA3_width) and\n",
    "        (y_point >= DG_CA3_bottom_left_y and y_point <= DG_CA3_bottom_left_y + DG_CA3_height) and\n",
    "        (z_point >= DG_CA3_bottom_left_z and z_point <= DG_CA3_bottom_left_z + DG_CA3_depth)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035000da-88b0-4f1b-bffc-e31159657b3e",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45be3d4c-fb4e-448f-973a-9708eac4042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the point is located within the CA1 region.\n",
    "def check_point_within_CA1_region(point, region_geometrics):\n",
    "\n",
    "    # Retrieving the x-coordinate, y-coordinate, and z-coordinate from the 'point' parameter.\n",
    "    x_point, y_point, z_point = point\n",
    "\n",
    "    # Retrieving the bottom left x-coordinate, y-coordinate, and z-coordinate of the left block of the CA1 region from the 'region_geometrics' parameter.\n",
    "    CA1_left_block_bottom_left_x, CA1_left_block_bottom_left_y, CA1_left_block_bottom_left_z  = region_geometrics['CA1_left_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the left block of the CA1 region from the 'region_geometrics' parameter.\n",
    "    CA1_left_block_width = region_geometrics['CA1_left_block']['width']\n",
    "    CA1_left_block_height = region_geometrics['CA1_left_block']['height']\n",
    "    CA1_left_block_depth = region_geometrics['CA1_left_block']['depth']\n",
    "\n",
    "    # Retrieving the bottom middle x-coordinate, y-coordinate, and z-coordinate of the middle block of the CA1 region from the 'region_geometrics' parameter.\n",
    "    CA1_middle_block_bottom_left_x, CA1_middle_block_bottom_left_y, CA1_middle_block_bottom_left_z  = region_geometrics['CA1_middle_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the middle block of the CA1 region from the 'region_geometrics' parameter.\n",
    "    CA1_middle_block_width = region_geometrics['CA1_middle_block']['width']\n",
    "    CA1_middle_block_height = region_geometrics['CA1_middle_block']['height']\n",
    "    CA1_middle_block_depth = region_geometrics['CA1_middle_block']['depth']\n",
    "\n",
    "    # Retrieving the bottom left x-coordinate, y-coordinate, and z-coordinate of the right block of the CA1 region from the 'region_geometrics' parameter.\n",
    "    CA1_right_block_bottom_left_x, CA1_right_block_bottom_left_y, CA1_right_block_bottom_left_z  = region_geometrics['CA1_right_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the right block of the CA1 region from the 'region_geometrics' parameter.\n",
    "    CA1_right_block_width = region_geometrics['CA1_right_block']['width']\n",
    "    CA1_right_block_height = region_geometrics['CA1_right_block']['height']\n",
    "    CA1_right_block_depth = region_geometrics['CA1_right_block']['depth']\n",
    "\n",
    "    # Checking whether the point is located within the left block of the CA1 region.\n",
    "    if ((x_point >= CA1_left_block_bottom_left_x and x_point <= CA1_left_block_bottom_left_x + CA1_left_block_width) and\n",
    "        (y_point >= CA1_left_block_bottom_left_y and y_point <= CA1_left_block_bottom_left_y + CA1_left_block_height) and\n",
    "        (z_point >= CA1_left_block_bottom_left_z and z_point <= CA1_left_block_bottom_left_z + CA1_left_block_depth)):\n",
    "        return True\n",
    "        \n",
    "    # Checking whether the point is located within the middle block of the CA1 region.\n",
    "    elif ((x_point >= CA1_middle_block_bottom_left_x and x_point <= CA1_middle_block_bottom_left_x + CA1_middle_block_width) and\n",
    "        (y_point >= CA1_middle_block_bottom_left_y and y_point <= CA1_middle_block_bottom_left_y + CA1_middle_block_height) and\n",
    "        (z_point >= CA1_middle_block_bottom_left_z and z_point <= CA1_middle_block_bottom_left_z + CA1_middle_block_depth)):\n",
    "        return True\n",
    "    \n",
    "    # Checking whether the point is located within the right block of the CA1 region.\n",
    "    elif ((x_point >= CA1_right_block_bottom_left_x and x_point <= CA1_right_block_bottom_left_x + CA1_right_block_width) and\n",
    "        (y_point >= CA1_right_block_bottom_left_y and y_point <= CA1_right_block_bottom_left_y + CA1_right_block_height) and\n",
    "        (z_point >= CA1_right_block_bottom_left_z and z_point <= CA1_right_block_bottom_left_z + CA1_right_block_depth)):\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cff0a4-97cc-4cd8-918d-4403698f5a3a",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc4a7d5-c3df-4012-a362-b8e76f3e796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the point is located within the Sub region.\n",
    "def check_point_within_Sub_region(point, region_geometrics):\n",
    "\n",
    "    # Retrieving the x-coordinate, y-coordinate, and z-coordinate from the 'point' parameter.\n",
    "    x_point, y_point, z_point = point\n",
    "\n",
    "    # Retrieving the bottom left x-coordinate, y-coordinate, and z-coordinate of the left block of the Sub region from the 'region_geometrics' parameter.\n",
    "    Sub_left_block_bottom_left_x, Sub_left_block_bottom_left_y, Sub_left_block_bottom_left_z  = region_geometrics['Sub_left_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the left block of the Sub region from the 'region_geometrics' parameter.\n",
    "    Sub_left_block_width = region_geometrics['Sub_left_block']['width']\n",
    "    Sub_left_block_height = region_geometrics['Sub_left_block']['height']\n",
    "    Sub_left_block_depth = region_geometrics['Sub_left_block']['depth']\n",
    "\n",
    "    # Retrieving the bottom left x-coordinate, y-coordinate, and z-coordinate of the right block of the Sub region from the 'region_geometrics' parameter.\n",
    "    Sub_right_block_bottom_left_x, Sub_right_block_bottom_left_y, Sub_right_block_bottom_left_z  = region_geometrics['Sub_right_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the right block of the Sub region from the 'region_geometrics' parameter.\n",
    "    Sub_right_block_width = region_geometrics['Sub_right_block']['width']\n",
    "    Sub_right_block_height = region_geometrics['Sub_right_block']['height']\n",
    "    Sub_right_block_depth = region_geometrics['Sub_right_block']['depth']\n",
    "\n",
    "    # Checking whether the point is located within the left block of the Sub region.\n",
    "    if ((x_point >= Sub_left_block_bottom_left_x and x_point <= Sub_left_block_bottom_left_x + Sub_left_block_width) and\n",
    "        (y_point >= Sub_left_block_bottom_left_y and y_point <= Sub_left_block_bottom_left_y + Sub_left_block_height) and\n",
    "        (z_point >= Sub_left_block_bottom_left_z and z_point <= Sub_left_block_bottom_left_z + Sub_left_block_depth)):\n",
    "        return True\n",
    "    \n",
    "    # Checking whether the point is located within the right block of the Sub region.\n",
    "    elif ((x_point >= Sub_right_block_bottom_left_x and x_point <= Sub_right_block_bottom_left_x + Sub_right_block_width) and\n",
    "        (y_point >= Sub_right_block_bottom_left_y and y_point <= Sub_right_block_bottom_left_y + Sub_right_block_height) and\n",
    "        (z_point >= Sub_right_block_bottom_left_z and z_point <= Sub_right_block_bottom_left_z + Sub_right_block_depth)):\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db164462-d67a-4062-93a2-162a1e7a2c40",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c9bf10-cd84-4046-adeb-7b5a145e98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the point is located within the EC region.\n",
    "def check_point_within_EC_region(point, region_geometrics):\n",
    "\n",
    "    # Retrieving the x-coordinate, y-coordinate, and z-coordinate from the 'point' parameter.\n",
    "    x_point, y_point, z_point = point\n",
    "\n",
    "    # Retrieving the bottom left x-coordinate, y-coordinate, and z-coordinate of the EC region from the 'region_geometrics' parameter.\n",
    "    EC_bottom_left_x, EC_bottom_left_y, EC_bottom_left_z  = region_geometrics['EC_block']['bottom_left_position']\n",
    "\n",
    "    # Retrieving the width, height, and width of the EC region from the 'region_geometrics' parameter.\n",
    "    EC_width = region_geometrics['EC_block']['width']\n",
    "    EC_height = region_geometrics['EC_block']['height']\n",
    "    EC_depth = region_geometrics['EC_block']['depth']\n",
    "\n",
    "    # Checking whether the point is located within the EC region.\n",
    "    if ((x_point >= EC_bottom_left_x and x_point <= EC_bottom_left_x + EC_width) and\n",
    "        (y_point >= EC_bottom_left_y and y_point <= EC_bottom_left_y + EC_height) and\n",
    "        (z_point >= EC_bottom_left_z and z_point <= EC_bottom_left_z + EC_depth)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808505a2-0078-441a-93d5-5d33446fd7a4",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a47486-78e3-40d8-a25a-6336560a84dd",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Topology and Neuron Groups Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef688cb0-19e8-433a-aef0-b918c5b9350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the complete neuron topology of the model taking into account the structure of the hippocampus.\n",
    "def create_complete_neuron_topology_hippocampus(desired_total_num_of_neurons, region_neuron_densities, region_volumes, region_excitatory_ratios, region_names):\n",
    "\n",
    "    ############################################################\n",
    "    ########  Calculating Number of Neurons per Region  ########\n",
    "    ############################################################\n",
    "    # Initializing a dictionary that will contain the number of neurons present in each of the regions and a variable that counts the total numbers of neurons.\n",
    "    num_of_neurons = {}\n",
    "    total_num_of_neurons = 0\n",
    "\n",
    "    # Looping over every region and calculating how many neurons are present in each of the regions depending on the neuron densities and the volumes of the regions.\n",
    "    for region in region_names:\n",
    "        num_of_neurons[region] = region_neuron_densities[region] * region_volumes[region]\n",
    "        total_num_of_neurons += num_of_neurons[region]\n",
    "\n",
    "    # Calculating the scaling factor for the number of neurons for all regions as we ideally only want to model a number similar to the 'desired_total_num_of_neurons'.\n",
    "    neuron_scaling_factor = desired_total_num_of_neurons / total_num_of_neurons\n",
    "\n",
    "    # Initializing a dictionary that will contain the adjusted number of neurons present in each of the regions and one that will contain the adjusted volume of each region.\n",
    "    num_of_neurons_adjusted = {}\n",
    "    region_volume_adjusted = {}\n",
    "\n",
    "    # Looping over every region and calculating how many neurons are present in each of the regions after having multiplied the original number with the 'neuron_scaling_factor'.\n",
    "    for region in region_names:\n",
    "        num_of_neurons_adjusted[region] = neuron_scaling_factor * num_of_neurons[region]\n",
    "        region_volume_adjusted[region] = neuron_scaling_factor * region_volumes[region]\n",
    "\n",
    "    # Creating a dictionary that will eventually contain all the region information.\n",
    "    region_data = {}\n",
    "    for region in region_names:\n",
    "        region_data[region] = {\"region_name\": region,\n",
    "                             \"volume\": region_volume_adjusted[region],\n",
    "                             \"num_excitatory_neurons\": region_excitatory_ratios[region] * num_of_neurons_adjusted[region],\n",
    "                             \"num_inhibitory_neurons\": (1 - region_excitatory_ratios[region]) * num_of_neurons_adjusted[region]}\n",
    "\n",
    "    # Initializing a dictionary that will eventually contain the geometrical information of the different building blocks of the regions.\n",
    "    region_geometrics = {}\n",
    "\n",
    "    \n",
    "    ############################################################\n",
    "    ########  Calculating Dimensions of DG_CA3 and CA1  ########\n",
    "    ############################################################\n",
    "    # Calculating the dimensions of the DG_CA3 region as it located within the CA1 region. Here, we assume it is a cube with equal dimensions which can be retrieved by calculating the cube root of its volume.\n",
    "    DG_CA3_dimensions = region_data['DG_CA3']['volume'] ** (1/3)\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the DG_CA3 region.\n",
    "    DG_CA3_block_volume = DG_CA3_dimensions * DG_CA3_dimensions * DG_CA3_dimensions\n",
    "    DG_CA3_block_volume_prop = DG_CA3_block_volume / region_data['DG_CA3']['volume']\n",
    "    DG_CA3_block_num_excitatory = int(region_data['DG_CA3']['num_excitatory_neurons'] * DG_CA3_block_volume_prop)\n",
    "    DG_CA3_block_num_inhibitory = int(region_data['DG_CA3']['num_inhibitory_neurons'] * DG_CA3_block_volume_prop)\n",
    "\n",
    "    # Calculating the total volume of the combined DG_CA3 and CA1 region by adding them together. \n",
    "    total_volume_DG_CA3_and_CA1 = region_data['DG_CA3']['volume'] + region_data['CA1']['volume']\n",
    "\n",
    "    # As the height of the CA1 region is a bit higher we can multiply the height of the DG_CA3 region with 1.2 (determined through inspection).\n",
    "    height_DG_CA3_and_CA1 = 1.2 * DG_CA3_dimensions\n",
    "\n",
    "    # Setting the depth of the combined DG_CA3 and CA1 block to be equal to the depth of the DG_CA3 region alone.\n",
    "    depth_DG_CA3_and_CA1 = DG_CA3_dimensions\n",
    "\n",
    "    # Calculating the width of the combined DG_CA3 and CA1 block by dividing the total volume by the product of the height and depth of the combined DG_CA3 and CA1 block.\n",
    "    width_DG_CA3_and_CA1 = total_volume_DG_CA3_and_CA1 / (height_DG_CA3_and_CA1 * depth_DG_CA3_and_CA1)\n",
    "\n",
    "    ####################\n",
    "    ## CA1 Left Block ##\n",
    "    ####################\n",
    "    # Calculating the width of the left block of the CA1 region by dividing the difference between the width of the DG_CA3 region and the width of the combined DG_CA3 and CA1 block by 2.\n",
    "    CA1_left_block_width = (width_DG_CA3_and_CA1 - DG_CA3_dimensions) / 2\n",
    "\n",
    "    # Setting the height and depth of the left block of the CA1 region to be equal to respectively the height and depth of the combined DG_CA3 and CA1 block.\n",
    "    CA1_left_block_height = height_DG_CA3_and_CA1\n",
    "    CA1_left_block_depth = depth_DG_CA3_and_CA1\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the left block of the CA1 region.\n",
    "    CA1_left_block_volume = CA1_left_block_width * CA1_left_block_height * CA1_left_block_depth\n",
    "    CA1_left_block_volume_prop = CA1_left_block_volume / region_data['CA1']['volume']\n",
    "    CA1_left_block_num_excitatory = int(region_data['CA1']['num_excitatory_neurons'] * CA1_left_block_volume_prop)\n",
    "    CA1_left_block_num_inhibitory = int(region_data['CA1']['num_inhibitory_neurons'] * CA1_left_block_volume_prop)\n",
    "    \n",
    "    ######################\n",
    "    ## CA1 Middle Block ##\n",
    "    ######################\n",
    "    # Calculating the height of the middle block of the CA1 region by subtracting the height of the DG_CA3 region from the height of the combined DG_CA3 and CA1 block.\n",
    "    CA1_middle_block_height = height_DG_CA3_and_CA1 - DG_CA3_dimensions\n",
    "\n",
    "    # Setting the width and depth of the middle block of the CA1 region to be equal to respectively the width of the DG_CA3 region and depth of the combined DG_CA3 and CA1 block.\n",
    "    CA1_middle_block_width = DG_CA3_dimensions\n",
    "    CA1_middle_block_depth = depth_DG_CA3_and_CA1\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the middle block of the CA1 region.\n",
    "    CA1_middle_block_volume = CA1_middle_block_width * CA1_middle_block_height * CA1_middle_block_depth\n",
    "    CA1_middle_block_volume_prop = CA1_middle_block_volume / region_data['CA1']['volume']\n",
    "    CA1_middle_block_num_excitatory = int(region_data['CA1']['num_excitatory_neurons'] * CA1_middle_block_volume_prop)\n",
    "    CA1_middle_block_num_inhibitory = int(region_data['CA1']['num_inhibitory_neurons'] * CA1_middle_block_volume_prop)\n",
    "\n",
    "    #####################\n",
    "    ## CA1 Right Block ##\n",
    "    #####################\n",
    "    # Calculating the width of the right block of the CA1 region by dividing the difference between the width of the DG_CA3 region and the width of the combined DG_CA3 and CA1 block by 2.\n",
    "    CA1_right_block_width = (width_DG_CA3_and_CA1 - DG_CA3_dimensions) / 2\n",
    "\n",
    "    # Setting the height and depth of the right block of the CA1 region to be equal to respectively the height and depth of the combined DG_CA3 and CA1 block.\n",
    "    CA1_right_block_height = height_DG_CA3_and_CA1\n",
    "    CA1_right_block_depth = depth_DG_CA3_and_CA1\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the right block of the CA1 region.\n",
    "    CA1_right_block_volume = CA1_right_block_width * CA1_right_block_height * CA1_right_block_depth\n",
    "    CA1_right_block_volume_prop = CA1_right_block_volume / region_data['CA1']['volume']\n",
    "    CA1_right_block_num_excitatory = int(region_data['CA1']['num_excitatory_neurons'] * CA1_right_block_volume_prop)\n",
    "    CA1_right_block_num_inhibitory = int(region_data['CA1']['num_inhibitory_neurons'] * CA1_right_block_volume_prop)\n",
    "\n",
    "    # Adding the geometrical information of the three CA1 blocks to the 'region_geometrics' dictionary.\n",
    "    CA1_left_block_x = 0\n",
    "    CA1_left_block_y = 0\n",
    "    CA1_left_block_z = 0\n",
    "    region_geometrics['CA1_left_block'] = {\"width\": CA1_left_block_width,\n",
    "                                         \"height\": CA1_left_block_height,\n",
    "                                         \"depth\": CA1_left_block_depth,\n",
    "                                         \"bottom_left_position\": [CA1_left_block_x, CA1_left_block_y, CA1_left_block_z],\n",
    "                                         \"num_excitatory_neurons\": CA1_left_block_num_excitatory,\n",
    "                                         \"num_inhibitory_neurons\": CA1_left_block_num_inhibitory\n",
    "                                         }\n",
    "    CA1_middle_block_x = CA1_left_block_x + CA1_left_block_width\n",
    "    CA1_middle_block_y = CA1_left_block_y\n",
    "    CA1_middle_block_z = 0\n",
    "    region_geometrics['CA1_middle_block'] = {\"width\": CA1_middle_block_width,\n",
    "                                           \"height\": CA1_middle_block_height,\n",
    "                                           \"depth\": CA1_middle_block_depth,\n",
    "                                           \"bottom_left_position\": [CA1_middle_block_x, CA1_middle_block_y, CA1_middle_block_z],\n",
    "                                           \"num_excitatory_neurons\": CA1_middle_block_num_excitatory,\n",
    "                                           \"num_inhibitory_neurons\": CA1_middle_block_num_inhibitory\n",
    "                                           }\n",
    "    CA1_right_block_x = CA1_middle_block_x + CA1_middle_block_width\n",
    "    CA1_right_block_y = CA1_middle_block_y\n",
    "    CA1_right_block_z = 0\n",
    "    region_geometrics['CA1_right_block'] = {\"width\": CA1_right_block_width,\n",
    "                                          \"height\": CA1_right_block_height,\n",
    "                                          \"depth\": CA1_right_block_depth,\n",
    "                                          \"bottom_left_position\": [CA1_right_block_x, CA1_right_block_y, CA1_right_block_z],\n",
    "                                          \"num_excitatory_neurons\": CA1_right_block_num_excitatory,\n",
    "                                          \"num_inhibitory_neurons\": CA1_right_block_num_inhibitory\n",
    "                                          }\n",
    "\n",
    "    # Adding the geometrical information of the DG_CA3 block to the 'region_geometrics' dictionary.\n",
    "    DG_CA3_block_x = CA1_left_block_x + CA1_left_block_width\n",
    "    DG_CA3_block_y = CA1_middle_block_y + CA1_middle_block_height\n",
    "    DG_CA3_block_z = 0\n",
    "    region_geometrics['DG_CA3_block'] = {\"width\": DG_CA3_dimensions,\n",
    "                                       \"height\": DG_CA3_dimensions,\n",
    "                                       \"depth\": DG_CA3_dimensions,\n",
    "                                       \"bottom_left_position\": [DG_CA3_block_x, DG_CA3_block_y, DG_CA3_block_z],\n",
    "                                       \"num_excitatory_neurons\": DG_CA3_block_num_excitatory,\n",
    "                                       \"num_inhibitory_neurons\": DG_CA3_block_num_inhibitory\n",
    "                                       }\n",
    "    \n",
    "\n",
    "    #################################################\n",
    "    ########  Calculating Dimensions of Sub  ########\n",
    "    #################################################\n",
    "    ####################\n",
    "    ## Sub Left Block ##\n",
    "    ####################\n",
    "    # Setting the width and depth of the left block of the Sub region to be equal to respectively the width and depth of the right block of the CA1 region.\n",
    "    Sub_left_block_width = CA1_right_block_width\n",
    "    Sub_left_block_depth = CA1_right_block_depth\n",
    "\n",
    "    # Calculating the height of the left block of the Sub region by dividing half of the total volume of the Sub region by the product of the width and depth of the left block of the Sub region.\n",
    "    Sub_left_block_height = (region_data['Sub']['volume'] / 2) / (Sub_left_block_width * Sub_left_block_depth)\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the left block of the Sub region.\n",
    "    Sub_left_block_volume = Sub_left_block_width * Sub_left_block_height * Sub_left_block_depth\n",
    "    Sub_left_block_volume_prop = Sub_left_block_volume / region_data['Sub']['volume']\n",
    "    Sub_left_block_num_excitatory = int(region_data['Sub']['num_excitatory_neurons'] * Sub_left_block_volume_prop)\n",
    "    Sub_left_block_num_inhibitory = int(region_data['Sub']['num_inhibitory_neurons'] * Sub_left_block_volume_prop)\n",
    "\n",
    "    #####################\n",
    "    ## Sub Right Block ##\n",
    "    #####################\n",
    "    # Setting the width, height, and depth of the right block of the Sub region to be equal to respectively the height, width, and depth of the left block of the Sub region (the right block is a 90 degree transformation of the left block).\n",
    "    Sub_right_block_width = Sub_left_block_height\n",
    "    Sub_right_block_height = Sub_left_block_width\n",
    "    Sub_right_block_depth = Sub_left_block_depth\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the right block of the Sub region.\n",
    "    Sub_right_block_volume = Sub_right_block_width * Sub_right_block_height * Sub_right_block_depth\n",
    "    Sub_right_block_volume_prop = Sub_right_block_volume / region_data['Sub']['volume']\n",
    "    Sub_right_block_num_excitatory = int(region_data['Sub']['num_excitatory_neurons'] * Sub_right_block_volume_prop)\n",
    "    Sub_right_block_num_inhibitory = int(region_data['Sub']['num_inhibitory_neurons'] * Sub_right_block_volume_prop)\n",
    "\n",
    "    # Adding the geometrical information of the two Sub blocks to the 'region_geometrics' dictionary.\n",
    "    Sub_left_block_x = CA1_right_block_x\n",
    "    Sub_left_block_y = CA1_right_block_y + CA1_right_block_height\n",
    "    Sub_left_block_z = 0\n",
    "    region_geometrics['Sub_left_block'] = {\"width\": Sub_left_block_width,\n",
    "                                         \"height\": Sub_left_block_height,\n",
    "                                         \"depth\": Sub_left_block_depth,\n",
    "                                         \"bottom_left_position\": [Sub_left_block_x, Sub_left_block_y, Sub_left_block_z],\n",
    "                                         \"num_excitatory_neurons\": Sub_left_block_num_excitatory,\n",
    "                                         \"num_inhibitory_neurons\": Sub_left_block_num_inhibitory\n",
    "                                         }\n",
    "    Sub_right_block_x = Sub_left_block_x + Sub_left_block_width\n",
    "    Sub_right_block_y = Sub_left_block_y + (Sub_left_block_height - Sub_right_block_height)\n",
    "    Sub_right_block_z = 0\n",
    "    region_geometrics['Sub_right_block'] = {\"width\": Sub_right_block_width,\n",
    "                                          \"height\": Sub_right_block_height,\n",
    "                                          \"depth\": Sub_right_block_depth,\n",
    "                                          \"bottom_left_position\": [Sub_right_block_x, Sub_right_block_y, Sub_right_block_z],\n",
    "                                          \"num_excitatory_neurons\": Sub_right_block_num_excitatory,\n",
    "                                          \"num_inhibitory_neurons\": Sub_right_block_num_inhibitory\n",
    "                                          }\n",
    "    \n",
    "\n",
    "    ################################################\n",
    "    ########  Calculating Dimensions of EC  ########\n",
    "    ################################################\n",
    "    # Setting the width and depth of the EC region to be equal to respectively the width and depth of the left block of the Sub region.\n",
    "    EC_width = Sub_left_block_width\n",
    "    EC_depth = Sub_left_block_depth\n",
    "\n",
    "    # Calculating the height of the EC region by dividing the volume of the EC layer by the product of the width and depth of the EC region.\n",
    "    EC_height = region_data['EC']['volume'] / (EC_width * EC_depth)\n",
    "\n",
    "    # Calculating how many excitatory and inhibitory neurons are present in the EC region.\n",
    "    EC_block_volume = EC_width * EC_height * EC_depth\n",
    "    EC_block_volume_prop = EC_block_volume / region_data['EC']['volume']\n",
    "    EC_block_num_excitatory = int(region_data['EC']['num_excitatory_neurons'] * EC_block_volume_prop)\n",
    "    EC_block_num_inhibitory = int(region_data['EC']['num_inhibitory_neurons'] * EC_block_volume_prop)\n",
    "\n",
    "    # Adding the geometrical information of the EC block to the 'region_geometrics' dictionary.\n",
    "    EC_block_x = Sub_right_block_x + Sub_right_block_width\n",
    "    EC_block_y = (Sub_right_block_y + Sub_right_block_height) - EC_height\n",
    "    EC_block_z = 0\n",
    "    region_geometrics['EC_block'] = {\"width\": EC_width,\n",
    "                                   \"height\": EC_height,\n",
    "                                   \"depth\": EC_depth,\n",
    "                                   \"bottom_left_position\": [EC_block_x, EC_block_y, EC_block_z],\n",
    "                                   \"num_excitatory_neurons\": EC_block_num_excitatory,\n",
    "                                   \"num_inhibitory_neurons\": EC_block_num_inhibitory\n",
    "                                   }\n",
    "\n",
    "    \n",
    "    ##########################################################\n",
    "    ########  Updating Number of Neurons Region Data  ########\n",
    "    ##########################################################\n",
    "    # Updating the number of excitatory and inhibitory neurons for each of the regions based on the number of neurons calculated for each of the blocks.\n",
    "    region_data['CA1']['num_excitatory_neurons'] = region_geometrics['CA1_left_block']['num_excitatory_neurons'] + region_geometrics['CA1_middle_block']['num_excitatory_neurons'] + region_geometrics['CA1_right_block']['num_excitatory_neurons']\n",
    "    region_data['CA1']['num_inhibitory_neurons'] = region_geometrics['CA1_left_block']['num_inhibitory_neurons'] + region_geometrics['CA1_middle_block']['num_inhibitory_neurons'] + region_geometrics['CA1_right_block']['num_inhibitory_neurons']\n",
    "    region_data['Sub']['num_excitatory_neurons'] = region_geometrics['Sub_left_block']['num_excitatory_neurons'] + region_geometrics['Sub_right_block']['num_excitatory_neurons']\n",
    "    region_data['Sub']['num_inhibitory_neurons'] = region_geometrics['Sub_left_block']['num_inhibitory_neurons'] + region_geometrics['Sub_right_block']['num_inhibitory_neurons']\n",
    "    region_data['DG_CA3']['num_excitatory_neurons'] = region_geometrics['DG_CA3_block']['num_excitatory_neurons']\n",
    "    region_data['DG_CA3']['num_inhibitory_neurons'] = region_geometrics['DG_CA3_block']['num_inhibitory_neurons']\n",
    "    region_data['EC']['num_excitatory_neurons'] = region_geometrics['EC_block']['num_excitatory_neurons']\n",
    "    region_data['EC']['num_inhibitory_neurons'] = region_geometrics['EC_block']['num_inhibitory_neurons']\n",
    "\n",
    "    \n",
    "    #############################################################\n",
    "    ########  Generating Random Points for every Region  ########\n",
    "    #############################################################\n",
    "    #########\n",
    "    ## CA1 ##\n",
    "    #########   \n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the CA1 region for the excitatory neurons.\n",
    "    CA1_left_block_x_exc = [random.uniform(region_geometrics['CA1_left_block']['bottom_left_position'][0], region_geometrics['CA1_left_block']['bottom_left_position'][0] + region_geometrics['CA1_left_block']['width']) for _ in range(region_geometrics['CA1_left_block']['num_excitatory_neurons'])]\n",
    "    CA1_left_block_y_exc = [random.uniform(region_geometrics['CA1_left_block']['bottom_left_position'][1], region_geometrics['CA1_left_block']['bottom_left_position'][1] + region_geometrics['CA1_left_block']['height']) for _ in range(region_geometrics['CA1_left_block']['num_excitatory_neurons'])]\n",
    "    CA1_left_block_z_exc = [random.uniform(region_geometrics['CA1_left_block']['bottom_left_position'][2], region_geometrics['CA1_left_block']['bottom_left_position'][2] + region_geometrics['CA1_left_block']['depth']) for _ in range(region_geometrics['CA1_left_block']['num_excitatory_neurons'])]\n",
    "    CA1_left_block_excitatory_topology = np.array([CA1_left_block_x_exc, CA1_left_block_y_exc, CA1_left_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the CA1 region for the inhibitory neurons.\n",
    "    CA1_left_block_x_inh = [random.uniform(region_geometrics['CA1_left_block']['bottom_left_position'][0], region_geometrics['CA1_left_block']['bottom_left_position'][0] + region_geometrics['CA1_left_block']['width']) for _ in range(region_geometrics['CA1_left_block']['num_inhibitory_neurons'])]\n",
    "    CA1_left_block_y_inh = [random.uniform(region_geometrics['CA1_left_block']['bottom_left_position'][1], region_geometrics['CA1_left_block']['bottom_left_position'][1] + region_geometrics['CA1_left_block']['height']) for _ in range(region_geometrics['CA1_left_block']['num_inhibitory_neurons'])]\n",
    "    CA1_left_block_z_inh = [random.uniform(region_geometrics['CA1_left_block']['bottom_left_position'][2], region_geometrics['CA1_left_block']['bottom_left_position'][2] + region_geometrics['CA1_left_block']['depth']) for _ in range(region_geometrics['CA1_left_block']['num_inhibitory_neurons'])]\n",
    "    CA1_left_block_inhibitory_topology = np.array([CA1_left_block_x_inh, CA1_left_block_y_inh, CA1_left_block_z_inh])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the middle block of the CA1 region for the excitatory neurons.\n",
    "    CA1_middle_block_x_exc = [random.uniform(region_geometrics['CA1_middle_block']['bottom_left_position'][0], region_geometrics['CA1_middle_block']['bottom_left_position'][0] + region_geometrics['CA1_middle_block']['width']) for _ in range(region_geometrics['CA1_middle_block']['num_excitatory_neurons'])]\n",
    "    CA1_middle_block_y_exc = [random.uniform(region_geometrics['CA1_middle_block']['bottom_left_position'][1], region_geometrics['CA1_middle_block']['bottom_left_position'][1] + region_geometrics['CA1_middle_block']['height']) for _ in range(region_geometrics['CA1_middle_block']['num_excitatory_neurons'])]\n",
    "    CA1_middle_block_z_exc = [random.uniform(region_geometrics['CA1_middle_block']['bottom_left_position'][2], region_geometrics['CA1_middle_block']['bottom_left_position'][2] + region_geometrics['CA1_middle_block']['depth']) for _ in range(region_geometrics['CA1_middle_block']['num_excitatory_neurons'])]\n",
    "    CA1_middle_block_excitatory_topology = np.array([CA1_middle_block_x_exc, CA1_middle_block_y_exc, CA1_middle_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the middle block of the CA1 region for the inhibitory neurons.\n",
    "    CA1_middle_block_x_inh = [random.uniform(region_geometrics['CA1_middle_block']['bottom_left_position'][0], region_geometrics['CA1_middle_block']['bottom_left_position'][0] + region_geometrics['CA1_middle_block']['width']) for _ in range(region_geometrics['CA1_middle_block']['num_inhibitory_neurons'])]\n",
    "    CA1_middle_block_y_inh = [random.uniform(region_geometrics['CA1_middle_block']['bottom_left_position'][1], region_geometrics['CA1_middle_block']['bottom_left_position'][1] + region_geometrics['CA1_middle_block']['height']) for _ in range(region_geometrics['CA1_middle_block']['num_inhibitory_neurons'])]\n",
    "    CA1_middle_block_z_inh = [random.uniform(region_geometrics['CA1_middle_block']['bottom_left_position'][2], region_geometrics['CA1_middle_block']['bottom_left_position'][2] + region_geometrics['CA1_middle_block']['depth']) for _ in range(region_geometrics['CA1_middle_block']['num_inhibitory_neurons'])]\n",
    "    CA1_middle_block_inhibitory_topology = np.array([CA1_middle_block_x_inh, CA1_middle_block_y_inh, CA1_middle_block_z_inh])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the right block of the CA1 region for the excitatory neurons.\n",
    "    CA1_right_block_x_exc = [random.uniform(region_geometrics['CA1_right_block']['bottom_left_position'][0], region_geometrics['CA1_right_block']['bottom_left_position'][0] + region_geometrics['CA1_right_block']['width']) for _ in range(region_geometrics['CA1_right_block']['num_excitatory_neurons'])]\n",
    "    CA1_right_block_y_exc = [random.uniform(region_geometrics['CA1_right_block']['bottom_left_position'][1], region_geometrics['CA1_right_block']['bottom_left_position'][1] + region_geometrics['CA1_right_block']['height']) for _ in range(region_geometrics['CA1_right_block']['num_excitatory_neurons'])]\n",
    "    CA1_right_block_z_exc = [random.uniform(region_geometrics['CA1_right_block']['bottom_left_position'][2], region_geometrics['CA1_right_block']['bottom_left_position'][2] + region_geometrics['CA1_right_block']['depth']) for _ in range(region_geometrics['CA1_right_block']['num_excitatory_neurons'])]\n",
    "    CA1_right_block_excitatory_topology = np.array([CA1_right_block_x_exc, CA1_right_block_y_exc, CA1_right_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the right block of the CA1 region for the inhibitory neurons.\n",
    "    CA1_right_block_x_inh = [random.uniform(region_geometrics['CA1_right_block']['bottom_left_position'][0], region_geometrics['CA1_right_block']['bottom_left_position'][0] + region_geometrics['CA1_right_block']['width']) for _ in range(region_geometrics['CA1_right_block']['num_inhibitory_neurons'])]\n",
    "    CA1_right_block_y_inh = [random.uniform(region_geometrics['CA1_right_block']['bottom_left_position'][1], region_geometrics['CA1_right_block']['bottom_left_position'][1] + region_geometrics['CA1_right_block']['height']) for _ in range(region_geometrics['CA1_right_block']['num_inhibitory_neurons'])]\n",
    "    CA1_right_block_z_inh = [random.uniform(region_geometrics['CA1_right_block']['bottom_left_position'][2], region_geometrics['CA1_right_block']['bottom_left_position'][2] + region_geometrics['CA1_right_block']['depth']) for _ in range(region_geometrics['CA1_right_block']['num_inhibitory_neurons'])]\n",
    "    CA1_right_block_inhibitory_topology = np.array([CA1_right_block_x_inh, CA1_right_block_y_inh, CA1_right_block_z_inh])\n",
    "    \n",
    "    #########\n",
    "    ## Sub ##\n",
    "    #########\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the Sub region for the excitatory neurons.\n",
    "    Sub_left_block_x_exc = [random.uniform(region_geometrics['Sub_left_block']['bottom_left_position'][0], region_geometrics['Sub_left_block']['bottom_left_position'][0] + region_geometrics['Sub_left_block']['width']) for _ in range(region_geometrics['Sub_left_block']['num_excitatory_neurons'])]\n",
    "    Sub_left_block_y_exc = [random.uniform(region_geometrics['Sub_left_block']['bottom_left_position'][1], region_geometrics['Sub_left_block']['bottom_left_position'][1] + region_geometrics['Sub_left_block']['height']) for _ in range(region_geometrics['Sub_left_block']['num_excitatory_neurons'])]\n",
    "    Sub_left_block_z_exc = [random.uniform(region_geometrics['Sub_left_block']['bottom_left_position'][2], region_geometrics['Sub_left_block']['bottom_left_position'][2] + region_geometrics['Sub_left_block']['depth']) for _ in range(region_geometrics['Sub_left_block']['num_excitatory_neurons'])]\n",
    "    Sub_left_block_excitatory_topology = np.array([Sub_left_block_x_exc, Sub_left_block_y_exc, Sub_left_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the Sub region for the inhibitory neurons.\n",
    "    Sub_left_block_x_inh = [random.uniform(region_geometrics['Sub_left_block']['bottom_left_position'][0], region_geometrics['Sub_left_block']['bottom_left_position'][0] + region_geometrics['Sub_left_block']['width']) for _ in range(region_geometrics['Sub_left_block']['num_inhibitory_neurons'])]\n",
    "    Sub_left_block_y_inh = [random.uniform(region_geometrics['Sub_left_block']['bottom_left_position'][1], region_geometrics['Sub_left_block']['bottom_left_position'][1] + region_geometrics['Sub_left_block']['height']) for _ in range(region_geometrics['Sub_left_block']['num_inhibitory_neurons'])]\n",
    "    Sub_left_block_z_inh = [random.uniform(region_geometrics['Sub_left_block']['bottom_left_position'][2], region_geometrics['Sub_left_block']['bottom_left_position'][2] + region_geometrics['Sub_left_block']['depth']) for _ in range(region_geometrics['Sub_left_block']['num_inhibitory_neurons'])]\n",
    "    Sub_left_block_inhibitory_topology = np.array([Sub_left_block_x_inh, Sub_left_block_y_inh, Sub_left_block_z_inh])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the right block of the Sub region for the excitatory neurons.\n",
    "    Sub_right_block_x_exc = [random.uniform(region_geometrics['Sub_right_block']['bottom_left_position'][0], region_geometrics['Sub_right_block']['bottom_left_position'][0] + region_geometrics['Sub_right_block']['width']) for _ in range(region_geometrics['Sub_right_block']['num_excitatory_neurons'])]\n",
    "    Sub_right_block_y_exc = [random.uniform(region_geometrics['Sub_right_block']['bottom_left_position'][1], region_geometrics['Sub_right_block']['bottom_left_position'][1] + region_geometrics['Sub_right_block']['height']) for _ in range(region_geometrics['Sub_right_block']['num_excitatory_neurons'])]\n",
    "    Sub_right_block_z_exc = [random.uniform(region_geometrics['Sub_right_block']['bottom_left_position'][2], region_geometrics['Sub_right_block']['bottom_left_position'][2] + region_geometrics['Sub_right_block']['depth']) for _ in range(region_geometrics['Sub_right_block']['num_excitatory_neurons'])]\n",
    "    Sub_right_block_excitatory_topology = np.array([Sub_right_block_x_exc, Sub_right_block_y_exc, Sub_right_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the right block of the Sub region for the inhibitory neurons.\n",
    "    Sub_right_block_x_inh = [random.uniform(region_geometrics['Sub_right_block']['bottom_left_position'][0], region_geometrics['Sub_right_block']['bottom_left_position'][0] + region_geometrics['Sub_right_block']['width']) for _ in range(region_geometrics['Sub_right_block']['num_inhibitory_neurons'])]\n",
    "    Sub_right_block_y_inh = [random.uniform(region_geometrics['Sub_right_block']['bottom_left_position'][1], region_geometrics['Sub_right_block']['bottom_left_position'][1] + region_geometrics['Sub_right_block']['height']) for _ in range(region_geometrics['Sub_right_block']['num_inhibitory_neurons'])]\n",
    "    Sub_right_block_z_inh = [random.uniform(region_geometrics['Sub_right_block']['bottom_left_position'][2], region_geometrics['Sub_right_block']['bottom_left_position'][2] + region_geometrics['Sub_right_block']['depth']) for _ in range(region_geometrics['Sub_right_block']['num_inhibitory_neurons'])]\n",
    "    Sub_right_block_inhibitory_topology = np.array([Sub_right_block_x_inh, Sub_right_block_y_inh, Sub_right_block_z_inh])\n",
    "\n",
    "    ############\n",
    "    ## DG_CA3 ##\n",
    "    ############\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the DG_CA3 region for the excitatory neurons.\n",
    "    DG_CA3_block_x_exc = [random.uniform(region_geometrics['DG_CA3_block']['bottom_left_position'][0], region_geometrics['DG_CA3_block']['bottom_left_position'][0] + region_geometrics['DG_CA3_block']['width']) for _ in range(region_geometrics['DG_CA3_block']['num_excitatory_neurons'])]\n",
    "    DG_CA3_block_y_exc = [random.uniform(region_geometrics['DG_CA3_block']['bottom_left_position'][1], region_geometrics['DG_CA3_block']['bottom_left_position'][1] + region_geometrics['DG_CA3_block']['height']) for _ in range(region_geometrics['DG_CA3_block']['num_excitatory_neurons'])]\n",
    "    DG_CA3_block_z_exc = [random.uniform(region_geometrics['DG_CA3_block']['bottom_left_position'][2], region_geometrics['DG_CA3_block']['bottom_left_position'][2] + region_geometrics['DG_CA3_block']['depth']) for _ in range(region_geometrics['DG_CA3_block']['num_excitatory_neurons'])]\n",
    "    DG_CA3_block_excitatory_topology = np.array([DG_CA3_block_x_exc, DG_CA3_block_y_exc, DG_CA3_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the DG_CA3 region for the inhibitory neurons.\n",
    "    DG_CA3_block_x_inh = [random.uniform(region_geometrics['DG_CA3_block']['bottom_left_position'][0], region_geometrics['DG_CA3_block']['bottom_left_position'][0] + region_geometrics['DG_CA3_block']['width']) for _ in range(region_geometrics['DG_CA3_block']['num_inhibitory_neurons'])]\n",
    "    DG_CA3_block_y_inh = [random.uniform(region_geometrics['DG_CA3_block']['bottom_left_position'][1], region_geometrics['DG_CA3_block']['bottom_left_position'][1] + region_geometrics['DG_CA3_block']['height']) for _ in range(region_geometrics['DG_CA3_block']['num_inhibitory_neurons'])]\n",
    "    DG_CA3_block_z_inh = [random.uniform(region_geometrics['DG_CA3_block']['bottom_left_position'][2], region_geometrics['DG_CA3_block']['bottom_left_position'][2] + region_geometrics['DG_CA3_block']['depth']) for _ in range(region_geometrics['DG_CA3_block']['num_inhibitory_neurons'])]\n",
    "    DG_CA3_block_inhibitory_topology = np.array([DG_CA3_block_x_inh, DG_CA3_block_y_inh, DG_CA3_block_z_inh])\n",
    "\n",
    "    ########\n",
    "    ## EC ##\n",
    "    ########\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the EC region for the excitatory neurons.\n",
    "    EC_block_x_exc = [random.uniform(region_geometrics['EC_block']['bottom_left_position'][0], region_geometrics['EC_block']['bottom_left_position'][0] + region_geometrics['EC_block']['width']) for _ in range(region_geometrics['EC_block']['num_excitatory_neurons'])]\n",
    "    EC_block_y_exc = [random.uniform(region_geometrics['EC_block']['bottom_left_position'][1], region_geometrics['EC_block']['bottom_left_position'][1] + region_geometrics['EC_block']['height']) for _ in range(region_geometrics['EC_block']['num_excitatory_neurons'])]\n",
    "    EC_block_z_exc = [random.uniform(region_geometrics['EC_block']['bottom_left_position'][2], region_geometrics['EC_block']['bottom_left_position'][2] + region_geometrics['EC_block']['depth']) for _ in range(region_geometrics['EC_block']['num_excitatory_neurons'])]\n",
    "    EC_block_excitatory_topology = np.array([EC_block_x_exc, EC_block_y_exc, EC_block_z_exc])\n",
    "\n",
    "    # Generating a set of random x, y, and z positions that fall within the left block of the EC region for the inhibitory neurons.\n",
    "    EC_block_x_inh = [random.uniform(region_geometrics['EC_block']['bottom_left_position'][0], region_geometrics['EC_block']['bottom_left_position'][0] + region_geometrics['EC_block']['width']) for _ in range(region_geometrics['EC_block']['num_inhibitory_neurons'])]\n",
    "    EC_block_y_inh = [random.uniform(region_geometrics['EC_block']['bottom_left_position'][1], region_geometrics['EC_block']['bottom_left_position'][1] + region_geometrics['EC_block']['height']) for _ in range(region_geometrics['EC_block']['num_inhibitory_neurons'])]\n",
    "    EC_block_z_inh = [random.uniform(region_geometrics['EC_block']['bottom_left_position'][2], region_geometrics['EC_block']['bottom_left_position'][2] + region_geometrics['EC_block']['depth']) for _ in range(region_geometrics['EC_block']['num_inhibitory_neurons'])]\n",
    "    EC_block_inhibitory_topology = np.array([EC_block_x_inh, EC_block_y_inh, EC_block_z_inh])\n",
    "\n",
    "    \n",
    "    ###################################################\n",
    "    ########  Combining Topologies per Region  ########\n",
    "    ###################################################\n",
    "    # Initializing two dictionaries that will for each region store the positions of the excitatory and inhibitory neurons.\n",
    "    excitatory_positions = {}\n",
    "    inhibitory_positions = {}\n",
    "\n",
    "    # Adding the excitatory and inhibitory topologies of the CA1 region to the 'excitatory_positions' and 'inhibitory_positions' dictionaries.\n",
    "    excitatory_positions['CA1'] = []\n",
    "    for sublist1, sublist2, sublist3 in zip_longest(CA1_left_block_excitatory_topology, CA1_middle_block_excitatory_topology, CA1_right_block_excitatory_topology, fillvalue=[]):\n",
    "        merged_sublist = list(chain(sublist1, sublist2, sublist3))\n",
    "        excitatory_positions['CA1'].append(merged_sublist)\n",
    "    inhibitory_positions['CA1'] = []\n",
    "    for sublist1, sublist2, sublist3 in zip_longest(CA1_left_block_inhibitory_topology, CA1_middle_block_inhibitory_topology, CA1_right_block_inhibitory_topology, fillvalue=[]):\n",
    "        merged_sublist = list(chain(sublist1, sublist2, sublist3))\n",
    "        inhibitory_positions['CA1'].append(merged_sublist)\n",
    "        \n",
    "    # Adding the excitatory and inhibitory topologies of the Sub region to the 'excitatory_positions' and 'inhibitory_positions' dictionaries.\n",
    "    excitatory_positions['Sub'] = []\n",
    "    for sublist1, sublist2 in zip_longest(Sub_left_block_excitatory_topology, Sub_right_block_excitatory_topology, fillvalue=[]):\n",
    "        merged_sublist = list(chain(sublist1, sublist2))\n",
    "        excitatory_positions['Sub'].append(merged_sublist)\n",
    "    inhibitory_positions['Sub'] = []\n",
    "    for sublist1, sublist2 in zip_longest(Sub_left_block_inhibitory_topology, Sub_right_block_inhibitory_topology, fillvalue=[]):\n",
    "        merged_sublist = list(chain(sublist1, sublist2))\n",
    "        inhibitory_positions['Sub'].append(merged_sublist)\n",
    "\n",
    "    # Adding the excitatory and inhibitory topologies of the DG_CA3 region to the 'excitatory_positions' and 'inhibitory_positions' dictionaries.\n",
    "    excitatory_positions['DG_CA3'] = DG_CA3_block_excitatory_topology\n",
    "    inhibitory_positions['DG_CA3'] = DG_CA3_block_inhibitory_topology\n",
    "\n",
    "    # Adding the excitatory and inhibitory topologies of the EC region to the 'excitatory_positions' and 'inhibitory_positions' dictionaries.\n",
    "    excitatory_positions['EC'] = EC_block_excitatory_topology\n",
    "    inhibitory_positions['EC'] = EC_block_inhibitory_topology\n",
    "\n",
    "    \n",
    "    return region_data, region_geometrics, excitatory_positions, inhibitory_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5386177-571d-4242-90bc-97665e4d72a5",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9391df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the group of excitatory neurons.\n",
    "def create_group_py(topology, noise, masks, current_region, stimulus_regions, treatment_regions, group_name='exc_group', integ_method='exponential_euler'):\n",
    "\n",
    "    # Extracting the passed on parameters.\n",
    "    x, y, z = topology\n",
    "    mu_noise, sigma_noise = noise\n",
    "    stimulus_mask, treatment_mask = masks\n",
    "\n",
    "    # Adjusting the group name.\n",
    "    group_name = group_name + \"_\" + current_region\n",
    "\n",
    "    # Initializing a group of excitatory neurons with the following parameters:\n",
    "    # - py_eqs => Differential equations that define the behavior of the excitatory neuron.\n",
    "    # - threshold => Neurons fire an action potential when their membrane potential 'v' exceeds the threshold 'V_th'.\n",
    "    # - reset => Resets neuron states after they fire according to 'reset_eqs'.\n",
    "    # - refractory => Sets a refractory period during which an excitatory neuron cannot fire again.\n",
    "    # - method => Specifies the integration method for solving the differential equations.\n",
    "    G_exc = NeuronGroup(len(x),py_eqs,threshold='v>V_th',reset=reset_eqs,refractory=3*ms,name=group_name, method=integ_method)\n",
    "\n",
    "    # Initializing the membrane potential 'v' to be a random value between -60 mV and -100 mV.\n",
    "    G_exc.v = '-60*mvolt-rand()*40*mvolt'\n",
    "\n",
    "    # Sets the neurotransmitter to be used to be glutamate (which is an excitatory neurotransmitter).\n",
    "    G_exc.glu = 1\n",
    "\n",
    "    # Assigns the positions of the neurons in micrometers.\n",
    "    G_exc.x = x * um\n",
    "    G_exc.y = y * um\n",
    "    G_exc.z = z * um\n",
    "\n",
    "    # Sets the size of the neurons to 'taille_exc_normale'.\n",
    "    G_exc.taille = taille_exc_normale\n",
    "\n",
    "    # Sets the mean and standard deviation of the noise affecting the neurons.\n",
    "    G_exc.mu_noise = mu_noise\n",
    "    G_exc.sigma_noise = sigma_noise\n",
    "\n",
    "    # Applying the treatment mask to the neuron by first checking whether the current region is in the list of treatment regions. If not, a list of zeros is added as treatment mask.\n",
    "    if current_region in treatment_regions:\n",
    "        G_exc.treatment_mask = treatment_mask\n",
    "    else:\n",
    "        G_exc.treatment_mask = np.zeros(len(x))\n",
    "\n",
    "    # Applying the stimulus mask to the neuron by first checking whether the current region is in the list of stimulus regions. If not, a list of zeros is added as stimulus mask.\n",
    "    if current_region in stimulus_regions:\n",
    "        G_exc.stimulus_mask = stimulus_mask\n",
    "    else:\n",
    "        G_exc.stimulus_mask = np.zeros(len(x))\n",
    "        \n",
    "    return G_exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74232f22-77a9-4268-8595-d3a38f03a400",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2a2423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the group of inhibitory neurons.\n",
    "def create_group_inh(topology, noise, treatment_mask, current_region, treatment_regions, group_name='inh_group', integ_method='exponential_euler'):\n",
    "\n",
    "    # Extracting the passed on parameters.\n",
    "    x, y, z = topology\n",
    "    mu_noise, sigma_noise = noise\n",
    "\n",
    "    # Adjusting the group name.\n",
    "    group_name = group_name + \"_\" + current_region\n",
    "\n",
    "    # Initializing a group of inhibitory neurons with the following parameters:\n",
    "    # - inh_eqs => Differential equations that define the behavior of the inhibitory neuron.\n",
    "    # - threshold => Neurons fire an action potential when their membrane potential 'v' exceeds the threshold 'V_th'.\n",
    "    # - refractory => Sets a refractory period during which an inhibitory neuron cannot fire again.\n",
    "    # - method => Specifies the integration method for solving the differential equations.\n",
    "    G_inh = NeuronGroup(len(x),inh_eqs,threshold='v>V_th', name=group_name, refractory=3*ms,method=integ_method)\n",
    "\n",
    "    # Initializing the membrane potential 'v' to be a random value between -60 mV and -70 mV.\n",
    "    G_inh.v = -60*mvolt-rand()*10*mvolt\n",
    "\n",
    "    # Sets the size of the neurons to 'taille_exc_normale'.\n",
    "    G_inh.taille = taille_inh_normale\n",
    "\n",
    "    # Assigns the positions of the neurons in micrometers.\n",
    "    G_inh.x = x * um\n",
    "    G_inh.y = y * um\n",
    "    G_inh.z = z * um\n",
    "\n",
    "    # Sets the mean and standard deviation of the noise affecting the neurons.\n",
    "    G_inh.mu_noise = mu_noise\n",
    "    G_inh.sigma_noise = sigma_noise\n",
    "\n",
    "    # Applying the treatment mask to the neuron by first checking whether the current region is in the list of treatment regions. If not, a list of zeros is added as treatment mask.\n",
    "    if current_region in treatment_regions:\n",
    "        G_inh.treatment_mask = treatment_mask\n",
    "    else:\n",
    "        G_inh.treatment_mask = np.zeros(len(x))\n",
    "\n",
    "    return G_inh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1857168-3caa-4f69-99eb-642b320a4f35",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b7a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a group for Local Field Potential (LFP) recording.\n",
    "def create_group_lfp(LFP_electrode_region, region_geometrics):\n",
    "    \n",
    "    # Setting up a singular LFP electrode\n",
    "    Ne = 1\n",
    "\n",
    "    # Setting the resistivity of the extracellular field to 0.3 siemens per meter, which is within the typical range for biological tissue (0.3-0.4 S/m).\n",
    "    sigma = 0.3*siemens/meter\n",
    "\n",
    "    # Initializes a group of neurons, which will only consist of 1 representing a single LFP electrode which has three state variables:\n",
    "    # - v : volt => Represents the voltage (LFP signal).\n",
    "    # - x : meter => Represent the x-coordinate of the electrode.\n",
    "    # - y : meter => Represent the y-coordinate of the electrode.\n",
    "    # - z : meter => Represent the z-coordinate of the electrode.\n",
    "    lfp = NeuronGroup(Ne, model='''v : volt\n",
    "                                   x : meter\n",
    "                                   y : meter\n",
    "                                   z : meter''')\n",
    "\n",
    "    # Defining the x, y, and z coordinates of the LFP electrode based on what the region of the LFP electrode is.\n",
    "    if LFP_electrode_region == \"DG_CA3\":\n",
    "        lfp.x = (region_geometrics['DG_CA3_block']['bottom_left_position'][0] + (region_geometrics['DG_CA3_block']['width'] / 2)) * mm\n",
    "        lfp.y = (region_geometrics['DG_CA3_block']['bottom_left_position'][1] + (region_geometrics['DG_CA3_block']['height'] / 2)) * mm\n",
    "        lfp.z = (region_geometrics['DG_CA3_block']['bottom_left_position'][2] + (region_geometrics['DG_CA3_block']['depth'] / 2)) * mm\n",
    "    if LFP_electrode_region == \"CA1\":\n",
    "        lfp.x = (region_geometrics['CA1_middle_block']['bottom_left_position'][0] + (region_geometrics['CA1_middle_block']['width'] / 2)) * mm\n",
    "        lfp.y = (region_geometrics['CA1_middle_block']['bottom_left_position'][1] + (region_geometrics['CA1_middle_block']['height'] / 2)) * mm\n",
    "        lfp.z = (region_geometrics['CA1_middle_block']['bottom_left_position'][2] + (region_geometrics['CA1_middle_block']['depth'] / 2)) * mm\n",
    "    if LFP_electrode_region == \"Sub\":\n",
    "        lfp.x = (region_geometrics['Sub_left_block']['bottom_left_position'][0] + (region_geometrics['Sub_left_block']['width'] / 2)) * mm\n",
    "        lfp.y = (region_geometrics['Sub_left_block']['bottom_left_position'][1] + (region_geometrics['Sub_left_block']['height'] / 2)) * mm\n",
    "        lfp.z = (region_geometrics['Sub_left_block']['bottom_left_position'][2] + (region_geometrics['Sub_left_block']['depth'] / 2)) * mm\n",
    "    if LFP_electrode_region == \"EC\":\n",
    "        lfp.x = (region_geometrics['EC_block']['bottom_left_position'][0] + (region_geometrics['EC_block']['width'] / 2)) * mm\n",
    "        lfp.y = (region_geometrics['EC_block']['bottom_left_position'][1] + (region_geometrics['EC_block']['height'] / 2)) * mm\n",
    "        lfp.z = (region_geometrics['EC_block']['bottom_left_position'][2] + (region_geometrics['EC_block']['depth'] / 2)) * mm\n",
    "\n",
    "    return lfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558578b8-54f0-43fc-9247-653d15cf7106",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3ba69-edad-4d16-b306-97fd660d3c91",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Network Configuration Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644b49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the network of neurons. The topology is already there, but the neurons still need to be connected, which is done here.\n",
    "def prepare_network(topologies, stimulus_mask_exc, treatment_masks, current_variables):\n",
    "\n",
    "    # Extracting the connection probabilities between neurons from the same region and from different regions.\n",
    "    probabilities_between_regions = current_variables['probabilities_between_regions']\n",
    "    probabilities_within_regions = current_variables['probabilities_within_regions']\n",
    "\n",
    "    # Extracting the topologies from the passed on parameter 'topologies'.\n",
    "    topology_DG_CA3_exc, topology_CA1_exc, topology_Sub_exc, topology_EC_exc, topology_DG_CA3_inh, topology_CA1_inh, topology_Sub_inh, topology_EC_inh = topologies\n",
    "\n",
    "    # Extracting the treatment masks from the passed on parameter 'treatment_masks'.\n",
    "    treatment_mask_exc, treatment_mask_inh = treatment_masks\n",
    "\n",
    "    \n",
    "    ##########################################\n",
    "    ########  Creating Neuron Groups  ########\n",
    "    ##########################################\n",
    "    # Creating excitatory neuron groups for each region.\n",
    "    G_DG_CA3_exc = create_group_py(topology_DG_CA3_exc, current_variables['noise_exc'], [stimulus_mask_exc, treatment_mask_exc], 'DG_CA3', current_variables['stimulus_regions'], current_variables['treatment_regions'])\n",
    "    G_CA1_exc = create_group_py(topology_CA1_exc, current_variables['noise_exc'], [stimulus_mask_exc, treatment_mask_exc], 'CA1', current_variables['stimulus_regions'], current_variables['treatment_regions'])\n",
    "    G_Sub_exc = create_group_py(topology_Sub_exc, current_variables['noise_exc'], [stimulus_mask_exc, treatment_mask_exc], 'Sub', current_variables['stimulus_regions'], current_variables['treatment_regions'])\n",
    "    G_EC_exc = create_group_py(topology_EC_exc, current_variables['noise_exc'], [stimulus_mask_exc, treatment_mask_exc], 'EC', current_variables['stimulus_regions'], current_variables['treatment_regions'])\n",
    "\n",
    "    # Creating inhibitory neuron groups for each region.\n",
    "    G_DG_CA3_inh = create_group_inh(topology_DG_CA3_inh, current_variables['noise_inh'], treatment_mask_inh, 'DG_CA3', current_variables['treatment_regions'])\n",
    "    G_CA1_inh = create_group_inh(topology_CA1_inh, current_variables['noise_inh'], treatment_mask_inh, 'CA1', current_variables['treatment_regions'])\n",
    "    G_Sub_inh = create_group_inh(topology_Sub_inh, current_variables['noise_inh'], treatment_mask_inh, 'Sub', current_variables['treatment_regions'])\n",
    "    G_EC_inh = create_group_inh(topology_EC_inh, current_variables['noise_inh'], treatment_mask_inh, 'EC', current_variables['treatment_regions'])\n",
    "\n",
    "    # Setting up a Local Field Potential (LFP) electrode.\n",
    "    G_lfp = create_group_lfp(current_variables['LFP_electrode_region'], current_variables['region_geometrics'])\n",
    "    \n",
    "    # Adding the neuron groups to a list.\n",
    "    neuron_groups = [G_DG_CA3_exc, G_CA1_exc, G_Sub_exc, G_EC_exc, G_DG_CA3_inh, G_CA1_inh, G_Sub_inh, G_EC_inh, G_lfp]\n",
    "\n",
    "    \n",
    "    #####################################\n",
    "    ########  Creating Monitors  ########\n",
    "    #####################################\n",
    "    # Setting up monitors that monitor the population firing rate of all excitatory and inhibitory neuron groups.\n",
    "    popmon_DG_CA3_exc = PopulationRateMonitor(G_DG_CA3_exc)\n",
    "    popmon_CA1_exc = PopulationRateMonitor(G_CA1_exc)\n",
    "    popmon_Sub_exc = PopulationRateMonitor(G_Sub_exc)\n",
    "    popmon_EC_exc = PopulationRateMonitor(G_EC_exc)\n",
    "    popmon_DG_CA3_inh = PopulationRateMonitor(G_DG_CA3_inh)\n",
    "    popmon_CA1_inh = PopulationRateMonitor(G_CA1_inh)\n",
    "    popmon_Sub_inh = PopulationRateMonitor(G_Sub_inh)\n",
    "    popmon_EC_inh = PopulationRateMonitor(G_EC_inh)\n",
    "\n",
    "    # Setting up a monitor that monitors the voltage of the LFP group.\n",
    "    Mlfp = StateMonitor(G_lfp, 'v', record=True)\n",
    "\n",
    "    # Setting up monitors that monitor the membrane potential, the noise current (and the stimulus current) for the selected excitatory/inhibitory neurons.\n",
    "    statemon_DG_CA3_exc = StateMonitor(G_DG_CA3_exc, ('v', 'I_stim', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_CA1_exc = StateMonitor(G_CA1_exc, ('v', 'I_stim', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_Sub_exc = StateMonitor(G_Sub_exc, ('v', 'I_stim', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_EC_exc = StateMonitor(G_EC_exc, ('v', 'I_stim', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_DG_CA3_inh = StateMonitor(G_DG_CA3_inh, ('v', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_CA1_inh = StateMonitor(G_CA1_inh, ('v', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_Sub_inh = StateMonitor(G_Sub_inh, ('v', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    statemon_EC_inh = StateMonitor(G_EC_inh, ('v', 'I_noise'), record=[1,2,3,4,5,6], dt=0.001*second)\n",
    "    monitors = [popmon_DG_CA3_exc, popmon_CA1_exc, popmon_Sub_exc, popmon_EC_exc, popmon_DG_CA3_inh, popmon_CA1_inh, popmon_Sub_inh, popmon_EC_inh, Mlfp, statemon_DG_CA3_exc, statemon_CA1_exc, statemon_Sub_exc, statemon_EC_exc, statemon_DG_CA3_inh, statemon_CA1_inh, statemon_Sub_inh, statemon_EC_inh]\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    ########  Connecting Neuron Groups  ########\n",
    "    ############################################\n",
    "    # Configuring synaptic connections between neuron groups where in the function call 'Synapses()' the first parameter is the pre-synaptic group and the second parameter is the post-synaptic group. \n",
    "    # The third parameter 'on_pre' specifies the action to be taken when a pre-synaptic neuron fires where the synaptic event will increase the post-synaptic event by a certain amount defined by:\n",
    "    # - gain => A scaling factor for the synaptic strength.\n",
    "    # - g_max/siemens => The maximum conductance for the type of synapse normalized by dividing by 'siemens' which is a unit of conductance.\n",
    "    # - glu_pre => The amount of glutamate released from the pre-synaptic neuron upon firing.\n",
    "    # MIND: This does not create synapses but instead only specifies their dynamics. The actual synapse connections are created by using the function 'connect()'.\n",
    "    synapses = []\n",
    "    \n",
    "    ################################      \n",
    "    ## Connections Within Regions ##\n",
    "    ################################\n",
    "    # Generating within the DG_CA3 region the connections between the groups of neurons which is a probabilistic process indicating that not all neurons are connected with each other but instead it is decided based on the provided probability and a distance measure.\n",
    "    S_DG_CA3_e2e = Synapses(G_DG_CA3_exc, G_DG_CA3_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_within_DG_CA3_e2e')\n",
    "    S_DG_CA3_e2i = Synapses(G_DG_CA3_exc, G_DG_CA3_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_within_DG_CA3_e2i')\n",
    "    S_DG_CA3_i2e = Synapses(G_DG_CA3_inh, G_DG_CA3_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_within_DG_CA3_i2e')\n",
    "    S_DG_CA3_e2e.connect(p=f'{probabilities_within_regions['DG_CA3_e2e']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_DG_CA3_e2i.connect(p=f'{probabilities_within_regions['DG_CA3_e2i']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_DG_CA3_i2e.connect(p=f'{probabilities_within_regions['DG_CA3_i2e']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    synapses.append(S_DG_CA3_e2e)\n",
    "    synapses.append(S_DG_CA3_e2i)\n",
    "    synapses.append(S_DG_CA3_i2e)\n",
    "\n",
    "    # Generating within the CA1 region the connections between the groups of neurons which is a probabilistic process indicating that not all neurons are connected with each other but instead it is decided based on the provided probability and a distance measure.\n",
    "    S_CA1_e2i = Synapses(G_CA1_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_within_CA1_e2i')\n",
    "    S_CA1_i2e = Synapses(G_CA1_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_within_CA1_i2e')\n",
    "    S_CA1_i2i = Synapses(G_CA1_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_within_CA1_i2i')\n",
    "    S_CA1_e2i.connect(p=f'{probabilities_within_regions['CA1_e2i']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_CA1_i2e.connect(p=f'{probabilities_within_regions['CA1_i2e']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_CA1_i2i.connect(p=f'{probabilities_within_regions['CA1_i2i']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    synapses.append(S_CA1_e2i)\n",
    "    synapses.append(S_CA1_i2e)\n",
    "    synapses.append(S_CA1_i2i)\n",
    "\n",
    "    # Generating within the Sub region the connections between the groups of neurons which is a probabilistic process indicating that not all neurons are connected with each other but instead it is decided based on the provided probability and a distance measure.\n",
    "    S_Sub_e2e = Synapses(G_Sub_exc, G_Sub_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_within_Sub_e2e')\n",
    "    S_Sub_e2i = Synapses(G_Sub_exc, G_Sub_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_within_Sub_e2i')\n",
    "    S_Sub_i2e = Synapses(G_Sub_inh, G_Sub_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_within_Sub_i2e')\n",
    "    S_Sub_i2i = Synapses(G_Sub_inh, G_Sub_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_within_Sub_i2i')\n",
    "    S_Sub_e2e.connect(p=f'{probabilities_within_regions['Sub_e2e']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_Sub_e2i.connect(p=f'{probabilities_within_regions['Sub_e2i']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_Sub_i2e.connect(p=f'{probabilities_within_regions['Sub_i2e']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_Sub_i2i.connect(p=f'{probabilities_within_regions['Sub_i2i']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    synapses.append(S_Sub_e2e)\n",
    "    synapses.append(S_Sub_e2i)\n",
    "    synapses.append(S_Sub_i2e)\n",
    "    synapses.append(S_Sub_i2i)\n",
    "\n",
    "    # Generating within the EC region the connections between the groups of neurons which is a probabilistic process indicating that not all neurons are connected with each other but instead it is decided based on the provided probability and a distance measure.\n",
    "    S_EC_e2i = Synapses(G_EC_exc, G_EC_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_within_EC_e2i')\n",
    "    S_EC_i2e = Synapses(G_EC_inh, G_EC_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_within_EC_i2e')\n",
    "    S_EC_e2i.connect(p=f'{probabilities_within_regions['EC_e2i']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_EC_i2e.connect(p=f'{probabilities_within_regions['EC_i2e']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    synapses.append(S_EC_e2i)\n",
    "    synapses.append(S_EC_i2e)\n",
    "\n",
    "    \n",
    "\n",
    "    #################################      \n",
    "    ## Connections Between Regions ##\n",
    "    #################################\n",
    "    # Generating from the DG_CA3 to the CA1 region the connections between the groups of neurons which is a probabilistic process indicating that not all neurons are connected with each other but instead it is decided based on the provided probability and a distance measure.\n",
    "    S_DG_CA3_CA1_e2e = Synapses(G_DG_CA3_exc, G_CA1_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_DG_CA3_CA1_e2e')\n",
    "    S_DG_CA3_CA1_e2i = Synapses(G_DG_CA3_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_DG_CA3_CA1_e2i')\n",
    "    S_DG_CA3_CA1_i2e = Synapses(G_DG_CA3_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_DG_CA3_CA1_i2e')\n",
    "    S_DG_CA3_CA1_i2i = Synapses(G_DG_CA3_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_DG_CA3_CA1_i2i')\n",
    "    S_DG_CA3_CA1_e2e.connect(p=f'{probabilities_between_regions['DG_CA3_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_DG_CA3_CA1_e2i.connect(p=f'{probabilities_between_regions['DG_CA3_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_DG_CA3_CA1_i2e.connect(p=f'{probabilities_between_regions['DG_CA3_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_DG_CA3_CA1_i2i.connect(p=f'{probabilities_between_regions['DG_CA3_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    synapses.append(S_DG_CA3_CA1_e2e)\n",
    "    synapses.append(S_DG_CA3_CA1_e2i)\n",
    "    synapses.append(S_DG_CA3_CA1_i2e)\n",
    "    synapses.append(S_DG_CA3_CA1_i2i)\n",
    "\n",
    "\n",
    "    # Generating from the CA1 to the Sub region the connections between the groups of neurons which is a probabilistic process indicating that not all neurons are connected with each other but instead it is decided based on the provided probability and a distance measure.\n",
    "    S_CA1_Sub_e2e = Synapses(G_CA1_exc, G_Sub_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_CA1_Sub_e2e')\n",
    "    S_CA1_Sub_e2i = Synapses(G_CA1_exc, G_Sub_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_CA1_Sub_e2i')\n",
    "    S_CA1_Sub_i2e = Synapses(G_CA1_inh, G_Sub_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_CA1_Sub_i2e')\n",
    "    S_CA1_Sub_i2i = Synapses(G_CA1_inh, G_Sub_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_CA1_Sub_i2i')\n",
    "    S_CA1_Sub_e2e.connect(p=f'{probabilities_between_regions['CA1_to_Sub']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_CA1_Sub_e2i.connect(p=f'{probabilities_between_regions['CA1_to_Sub']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_CA1_Sub_i2e.connect(p=f'{probabilities_between_regions['CA1_to_Sub']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    S_CA1_Sub_i2i.connect(p=f'{probabilities_between_regions['CA1_to_Sub']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    synapses.append(S_CA1_Sub_e2e)\n",
    "    synapses.append(S_CA1_Sub_e2i)\n",
    "    synapses.append(S_CA1_Sub_i2e)\n",
    "    synapses.append(S_CA1_Sub_i2i)\n",
    "\n",
    "    \n",
    "    # Since we want the total number of connections from the CA1 to the EC region to be equal when only using the given probability versus when using both the given probability and distance measure, we can examine how many connections are made for each case.\n",
    "    # This is done separately for all four possible combinations of neuron type connections.\n",
    "    testing_S_CA1_EC_e2e_no_dist = Synapses(G_CA1_exc, G_EC_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_CA1_EC_e2e_dist = Synapses(G_CA1_exc, G_EC_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_CA1_EC_e2e_no_dist.connect(p=probabilities_between_regions['CA1_to_EC'])\n",
    "    testing_S_CA1_EC_e2e_dist.connect(p=f'{probabilities_between_regions['CA1_to_EC']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_CA1_EC_e2e = len(testing_S_CA1_EC_e2e_dist.N_outgoing_pre) / len(testing_S_CA1_EC_e2e_no_dist.N_outgoing_pre)\n",
    "    \n",
    "    testing_S_CA1_EC_e2i_no_dist = Synapses(G_CA1_exc, G_EC_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_CA1_EC_e2i_dist = Synapses(G_CA1_exc, G_EC_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_CA1_EC_e2i_no_dist.connect(p=probabilities_between_regions['CA1_to_EC'])\n",
    "    testing_S_CA1_EC_e2i_dist.connect(p=f'{probabilities_between_regions['CA1_to_EC']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_CA1_EC_e2i = len(testing_S_CA1_EC_e2i_dist.N_outgoing_pre) / len(testing_S_CA1_EC_e2i_no_dist.N_outgoing_pre)\n",
    "\n",
    "    testing_S_CA1_EC_i2e_no_dist = Synapses(G_CA1_inh, G_EC_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_CA1_EC_i2e_dist = Synapses(G_CA1_inh, G_EC_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_CA1_EC_i2e_no_dist.connect(p=probabilities_between_regions['CA1_to_EC'])\n",
    "    testing_S_CA1_EC_i2e_dist.connect(p=f'{probabilities_between_regions['CA1_to_EC']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_CA1_EC_i2e = len(testing_S_CA1_EC_i2e_dist.N_outgoing_pre) / len(testing_S_CA1_EC_i2e_no_dist.N_outgoing_pre)\n",
    "\n",
    "    testing_S_CA1_EC_i2i_no_dist = Synapses(G_CA1_inh, G_EC_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_CA1_EC_i2i_dist = Synapses(G_CA1_inh, G_EC_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_CA1_EC_i2i_no_dist.connect(p=probabilities_between_regions['CA1_to_EC'])\n",
    "    testing_S_CA1_EC_i2i_dist.connect(p=f'{probabilities_between_regions['CA1_to_EC']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_CA1_EC_i2i = len(testing_S_CA1_EC_i2i_dist.N_outgoing_pre) / len(testing_S_CA1_EC_i2i_no_dist.N_outgoing_pre)\n",
    "\n",
    "    # These ratios can be used to multiply with the given probability in the 'connect()' function to ensure that the same number of connections would have been made if the distance measure was also included in the probability.\n",
    "    S_CA1_EC_e2e = Synapses(G_CA1_exc, G_EC_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_CA1_EC_e2e')\n",
    "    S_CA1_EC_e2i = Synapses(G_CA1_exc, G_EC_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_CA1_EC_e2i')\n",
    "    S_CA1_EC_i2e = Synapses(G_CA1_inh, G_EC_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_CA1_EC_i2e')\n",
    "    S_CA1_EC_i2i = Synapses(G_CA1_inh, G_EC_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_CA1_EC_i2i')\n",
    "    S_CA1_EC_e2e.connect(p=probabilities_between_regions['CA1_to_EC']*ratio_CA1_EC_e2e)\n",
    "    S_CA1_EC_e2i.connect(p=probabilities_between_regions['CA1_to_EC']*ratio_CA1_EC_e2i)\n",
    "    S_CA1_EC_i2e.connect(p=probabilities_between_regions['CA1_to_EC']*ratio_CA1_EC_i2e)\n",
    "    S_CA1_EC_i2i.connect(p=probabilities_between_regions['CA1_to_EC']*ratio_CA1_EC_i2i)\n",
    "    synapses.append(S_CA1_EC_e2e)\n",
    "    synapses.append(S_CA1_EC_e2i)\n",
    "    synapses.append(S_CA1_EC_i2e)\n",
    "    synapses.append(S_CA1_EC_i2i)\n",
    "\n",
    "    \n",
    "    # Since we want the total number of connections from the EC to the DG_CA3 region to be equal when only using the given probability versus when using both the given probability and distance measure, we can examine how many connections are made for each case.\n",
    "    # This is done separately for all four possible combinations of neuron type connections.\n",
    "    testing_S_EC_DG_CA3_e2e_no_dist = Synapses(G_EC_exc, G_DG_CA3_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_DG_CA3_e2e_dist = Synapses(G_EC_exc, G_DG_CA3_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_DG_CA3_e2e_no_dist.connect(p=probabilities_between_regions['EC_to_DG_CA3'])\n",
    "    testing_S_EC_DG_CA3_e2e_dist.connect(p=f'{probabilities_between_regions['EC_to_DG_CA3']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_DG_CA3_e2e = len(testing_S_EC_DG_CA3_e2e_dist.N_outgoing_pre) / len(testing_S_EC_DG_CA3_e2e_no_dist.N_outgoing_pre)\n",
    "    \n",
    "    testing_S_EC_DG_CA3_e2i_no_dist = Synapses(G_EC_exc, G_DG_CA3_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_DG_CA3_e2i_dist = Synapses(G_EC_exc, G_DG_CA3_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_DG_CA3_e2i_no_dist.connect(p=probabilities_between_regions['EC_to_DG_CA3'])\n",
    "    testing_S_EC_DG_CA3_e2i_dist.connect(p=f'{probabilities_between_regions['EC_to_DG_CA3']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_DG_CA3_e2i = len(testing_S_EC_DG_CA3_e2i_dist.N_outgoing_pre) / len(testing_S_EC_DG_CA3_e2i_no_dist.N_outgoing_pre)\n",
    "\n",
    "    testing_S_EC_DG_CA3_i2e_no_dist = Synapses(G_EC_inh, G_DG_CA3_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_DG_CA3_i2e_dist = Synapses(G_EC_inh, G_DG_CA3_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_DG_CA3_i2e_no_dist.connect(p=probabilities_between_regions['EC_to_DG_CA3'])\n",
    "    testing_S_EC_DG_CA3_i2e_dist.connect(p=f'{probabilities_between_regions['EC_to_DG_CA3']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_DG_CA3_i2e = len(testing_S_EC_DG_CA3_i2e_dist.N_outgoing_pre) / len(testing_S_EC_DG_CA3_i2e_no_dist.N_outgoing_pre)\n",
    "\n",
    "    testing_S_EC_DG_CA3_i2i_no_dist = Synapses(G_EC_inh, G_DG_CA3_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_DG_CA3_i2i_dist = Synapses(G_EC_inh, G_DG_CA3_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_DG_CA3_i2i_no_dist.connect(p=probabilities_between_regions['EC_to_DG_CA3'])\n",
    "    testing_S_EC_DG_CA3_i2i_dist.connect(p=f'{probabilities_between_regions['EC_to_DG_CA3']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_DG_CA3_i2i = len(testing_S_EC_DG_CA3_i2i_dist.N_outgoing_pre) / len(testing_S_EC_DG_CA3_i2i_no_dist.N_outgoing_pre)\n",
    "\n",
    "    # These ratios can be used to multiply with the given probability in the 'connect()' function to ensure that the same number of connections would have been made if the distance measure was also included in the probability.\n",
    "    S_EC_DG_CA3_e2e = Synapses(G_EC_exc, G_DG_CA3_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_EC_DG_CA3_e2e')\n",
    "    S_EC_DG_CA3_e2i = Synapses(G_EC_exc, G_DG_CA3_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_EC_DG_CA3_e2i')\n",
    "    S_EC_DG_CA3_i2e = Synapses(G_EC_inh, G_DG_CA3_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_EC_DG_CA3_i2e')\n",
    "    S_EC_DG_CA3_i2i = Synapses(G_EC_inh, G_DG_CA3_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_EC_DG_CA3_i2i')\n",
    "    S_EC_DG_CA3_e2e.connect(p=probabilities_between_regions['EC_to_DG_CA3']*ratio_EC_DG_CA3_e2e)\n",
    "    S_EC_DG_CA3_e2i.connect(p=probabilities_between_regions['EC_to_DG_CA3']*ratio_EC_DG_CA3_e2i)\n",
    "    S_EC_DG_CA3_i2e.connect(p=probabilities_between_regions['EC_to_DG_CA3']*ratio_EC_DG_CA3_i2e)\n",
    "    S_EC_DG_CA3_i2i.connect(p=probabilities_between_regions['EC_to_DG_CA3']*ratio_EC_DG_CA3_i2i)\n",
    "    synapses.append(S_EC_DG_CA3_e2e)\n",
    "    synapses.append(S_EC_DG_CA3_e2i)\n",
    "    synapses.append(S_EC_DG_CA3_i2e)\n",
    "    synapses.append(S_EC_DG_CA3_i2i)\n",
    "\n",
    "    \n",
    "    # Since we want the total number of connections from the EC to the CA1 region to be equal when only using the given probability versus when using both the given probability and distance measure, we can examine how many connections are made for each case.\n",
    "    # This is done separately for all four possible combinations of neuron type connections.\n",
    "    testing_S_EC_CA1_e2e_no_dist = Synapses(G_EC_exc, G_CA1_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_CA1_e2e_dist = Synapses(G_EC_exc, G_CA1_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_CA1_e2e_no_dist.connect(p=probabilities_between_regions['EC_to_CA1'])\n",
    "    testing_S_EC_CA1_e2e_dist.connect(p=f'{probabilities_between_regions['EC_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_CA1_e2e = len(testing_S_EC_CA1_e2e_dist.N_outgoing_pre) / len(testing_S_EC_CA1_e2e_no_dist.N_outgoing_pre)\n",
    "    \n",
    "    testing_S_EC_CA1_e2i_no_dist = Synapses(G_EC_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_CA1_e2i_dist = Synapses(G_EC_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\")\n",
    "    testing_S_EC_CA1_e2i_no_dist.connect(p=probabilities_between_regions['EC_to_CA1'])\n",
    "    testing_S_EC_CA1_e2i_dist.connect(p=f'{probabilities_between_regions['EC_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_CA1_e2i = len(testing_S_EC_CA1_e2i_dist.N_outgoing_pre) / len(testing_S_EC_CA1_e2i_no_dist.N_outgoing_pre)\n",
    "\n",
    "    testing_S_EC_CA1_i2e_no_dist = Synapses(G_EC_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_CA1_i2e_dist = Synapses(G_EC_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_CA1_i2e_no_dist.connect(p=probabilities_between_regions['EC_to_CA1'])\n",
    "    testing_S_EC_CA1_i2e_dist.connect(p=f'{probabilities_between_regions['EC_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_CA1_i2e = len(testing_S_EC_CA1_i2e_dist.N_outgoing_pre) / len(testing_S_EC_CA1_i2e_no_dist.N_outgoing_pre)\n",
    "\n",
    "    testing_S_EC_CA1_i2i_no_dist = Synapses(G_EC_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_CA1_i2i_dist = Synapses(G_EC_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\")\n",
    "    testing_S_EC_CA1_i2i_no_dist.connect(p=probabilities_between_regions['EC_to_CA1'])\n",
    "    testing_S_EC_CA1_i2i_dist.connect(p=f'{probabilities_between_regions['EC_to_CA1']}*exp(-(((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2) / (({489.9}*umeter)**2)))')\n",
    "    ratio_EC_CA1_i2i = len(testing_S_EC_CA1_i2i_dist.N_outgoing_pre) / len(testing_S_EC_CA1_i2i_no_dist.N_outgoing_pre)\n",
    "\n",
    "    # These ratios can be used to multiply with the given probability in the 'connect()' function to ensure that the same number of connections would have been made if the distance measure was also included in the probability.\n",
    "    S_EC_CA1_e2e = Synapses(G_EC_exc, G_CA1_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_EC_CA1_e2e')\n",
    "    S_EC_CA1_e2i = Synapses(G_EC_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\", name='synapses_between_EC_CA1_e2i')\n",
    "    S_EC_CA1_i2e = Synapses(G_EC_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_EC_CA1_i2e')\n",
    "    S_EC_CA1_i2i = Synapses(G_EC_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\", name='synapses_between_EC_CA1_i2i')\n",
    "    S_EC_CA1_e2e.connect(p=probabilities_between_regions['EC_to_CA1']*ratio_EC_CA1_e2e)\n",
    "    S_EC_CA1_e2i.connect(p=probabilities_between_regions['EC_to_CA1']*ratio_EC_CA1_e2i)\n",
    "    S_EC_CA1_i2e.connect(p=probabilities_between_regions['EC_to_CA1']*ratio_EC_CA1_i2e)\n",
    "    S_EC_CA1_i2i.connect(p=probabilities_between_regions['EC_to_CA1']*ratio_EC_CA1_i2i)\n",
    "    synapses.append(S_EC_CA1_e2e)\n",
    "    synapses.append(S_EC_CA1_e2i)\n",
    "    synapses.append(S_EC_CA1_i2e)\n",
    "    synapses.append(S_EC_CA1_i2i)\n",
    "\n",
    "    \n",
    "    ########################################################      \n",
    "    ## Connections Between Electrode and Electrode Region ##\n",
    "    ########################################################\n",
    "    # Configuring synaptic connections between the excitatory neurons and the LFP electrode based on what the region of the LFP electrode is.\n",
    "    if current_variables['LFP_electrode_region'] == \"DG_CA3\":\n",
    "        S_lfp = Synapses(G_DG_CA3_exc, G_lfp, model='''w : ohm*meter**2 (constant) # Weight in the LFP calculation\n",
    "                                               v_post = w*((0.0*amp/meter**2)-Im_pre) : volt (summed)''')\n",
    "    if current_variables['LFP_electrode_region'] == \"CA1\":\n",
    "        S_lfp = Synapses(G_CA1_exc, G_lfp, model='''w : ohm*meter**2 (constant) # Weight in the LFP calculation\n",
    "                                       v_post = w*((0.0*amp/meter**2)-Im_pre) : volt (summed)''')\n",
    "    if current_variables['LFP_electrode_region'] == \"Sub\":\n",
    "        S_lfp = Synapses(G_Sub_exc, G_lfp, model='''w : ohm*meter**2 (constant) # Weight in the LFP calculation\n",
    "                                       v_post = w*((0.0*amp/meter**2)-Im_pre) : volt (summed)''')\n",
    "    if current_variables['LFP_electrode_region'] == \"EC\":\n",
    "        S_lfp = Synapses(G_EC_exc, G_lfp, model='''w : ohm*meter**2 (constant) # Weight in the LFP calculation\n",
    "                                       v_post = w*((0.0*amp/meter**2)-Im_pre) : volt (summed)''')\n",
    "\n",
    "    # Ensuring LFP voltage is updated after neuron groups.\n",
    "    S_lfp.summed_updaters['v_post'].when = 'after_groups' \n",
    "\n",
    "    # Generating the connections between the excitatory neurons and the LFP electrode. Here, all of them will be connected since there is no probability defined.\n",
    "    S_lfp.connect()\n",
    "\n",
    "    # Setting the weight for LFP calculation which is scaled by the Euclidean distance measure.\n",
    "    S_lfp.w = '(29e3 * umetre ** 2)/(4*pi*sigma)/((x_pre-x_post)**2+(y_pre-y_post)**2+(z_pre-z_post)**2)**.5'\n",
    "\n",
    "    synapses.append(S_lfp)\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    ########  Final Network Definition  ########\n",
    "    ############################################\n",
    "    net = Network(neuron_groups, synapses, monitors)\n",
    "\n",
    "    \n",
    "    return net, synapses, monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2d875-6c5a-4dfc-9164-127b36ac8de5",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b1d3c-cddb-48f2-bd18-558925b4ba68",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Simulation Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb10c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the simulation of the neural network in discrete time fragments which includes a mechanism to alter neuron parameters based on a firing rate threshold, which simulates a treatment effect.\n",
    "def run_granular_simulation(net, variables, treatment_settings, monitors):\n",
    "    \n",
    "    print('#######################')\n",
    "    print('# Starting Simulation #')\n",
    "    print('#######################')\n",
    "    print()\n",
    "\n",
    "    # Extracting the passed on parameters.\n",
    "    total_duration = variables['duration']\n",
    "    input_signal = read_input_signal(variables['input_signal_file'])\n",
    "    time_fragment, firing_rate_threshold = treatment_settings\n",
    "    popmon_DG_CA3_exc, popmon_CA1_exc, popmon_Sub_exc, popmon_EC_exc, popmon_DG_CA3_inh, popmon_CA1_inh, popmon_Sub_inh, popmon_EC_inh, Mlfp, statemon_DG_CA3_exc, statemon_CA1_exc, statemon_Sub_exc, statemon_EC_exc, statemon_DG_CA3_inh, statemon_CA1_inh, statemon_Sub_inh, statemon_EC_inh = monitors\n",
    "    \n",
    "    # Setting the potassium equilibrium potentials for both the excitatory and inhibitory neurons.\n",
    "    Eke = variables['Eke_baseline']\n",
    "    Eki = variables['Eki_baseline']\n",
    "    Eke_baseline = variables['Eke_baseline']\n",
    "    Eki_baseline = variables['Eki_baseline']\n",
    "    \n",
    "    print('Treatment Parameters:', 'time sensitivity', time_fragment, 'FR Threshold:', firing_rate_threshold)\n",
    "    print()\n",
    "\n",
    "    # Converting the time fragments to milliseconds and determining the number of batches.\n",
    "    time_fragment_ms = int(time_fragment/ms)\n",
    "    num_batches = int(total_duration / time_fragment)\n",
    "\n",
    "    # Setting the population monitor of which the average firing rate will be evaluated to be the one corresponding to the topology the stimulus is in.\n",
    "    if variables['stimulus_regions'][0] == \"DG_CA3\":\n",
    "        population_monitor = popmon_DG_CA3_exc\n",
    "    elif variables['stimulus_regions'][0] == \"CA1\":\n",
    "        population_monitor = popmon_CA1_exc\n",
    "\n",
    "    # For every batch, we run the simulation on the network 'net'. Here the 'tqdm()' function is used which creates a progress bar.\n",
    "    for i in tqdm(range(num_batches), desc=\"Running Simulation\"): \n",
    "        net.run(time_fragment)\n",
    "\n",
    "        # If after running a time fragment, the average firing rate of the excitatory neurons over the last time fragment exceeds the threshold, treatment is initiated.\n",
    "        # This statement refers to the scenario where epilepsy is detected and treated by adjusting the potassium equilibrium potentials of the excitatory and inhibitory neurons.\n",
    "        if np.mean(population_monitor.rate[-time_fragment_ms:]) > firing_rate_threshold:\n",
    "            Eke = variables['Eke_treatment']\n",
    "            Eki = variables['Eki_treatment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab6714-6985-4982-8954-75ed1c8a8eae",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e34f6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function manages the overall process of setting up and running multiple instances of a neural network simulation as after setting everything up, the function 'run_granular_simulation()' is called.\n",
    "# In addition, it also handles the storing of the results.\n",
    "def run_model_loop(variables):\n",
    "\n",
    "    # Checking whether lengths of each variable list is equal.\n",
    "    if not check_dict_lenghts(variables):\n",
    "        raise ValueError('Lenghts of each variable list has be to equal!')\n",
    "    \n",
    "    # For every run provided in the 'run_id' field of the variables dictionary we perform the simulation (which requires some setting up first).\n",
    "    for i in range(len(variables['run_id'])):\n",
    "        \n",
    "        ##########################################\n",
    "        ########  Basic Simulation Setup  ########\n",
    "        ##########################################\n",
    "        # Resetting the state of the simulation environment (to avoid interference from the previous run) and seeting the default simulation time step.\n",
    "        start_scope()\n",
    "        defaultclock.dt = 0.001*second   \n",
    "\n",
    "        # Extracting the list of variables required for the current run.\n",
    "        current_variables = {key: variables[key][i] for key in variables}\n",
    "        print(current_variables['noise_exc'])\n",
    "\n",
    "        # Retrieving the treatment settings.\n",
    "        treatment_settings = [current_variables['device_sensitivity'], current_variables['firing_rate_threshold']]\n",
    "\n",
    "        # Creating a folder to store the results.\n",
    "        run_id = current_variables['run_id']\n",
    "        os.mkdir(f'./results/{run_id}')\n",
    "        write_run_settings(current_variables, run_id)\n",
    "\n",
    "        \n",
    "        #######################################\n",
    "        ########  Creating Topologies  ########\n",
    "        #######################################\n",
    "        # Creating the topologies of both the excitatory and inhibitory neurons.\n",
    "        region_data, region_geometrics, excitatory_positions, inhibitory_positions = create_complete_neuron_topology_hippocampus(current_variables['N'], current_variables['region_densities'], current_variables['region_volumes'], current_variables['excitatory_ratios'], current_variables['region_names'])\n",
    "\n",
    "        # Assigning the topologies of the excitatory neurons of the different regions to separate variables.\n",
    "        topology_DG_CA3_exc = excitatory_positions['DG_CA3']\n",
    "        topology_CA1_exc = excitatory_positions['CA1']\n",
    "        topology_Sub_exc = excitatory_positions['Sub']\n",
    "        topology_EC_exc = excitatory_positions['EC']\n",
    "\n",
    "        # Assigning the topologies of the inhibitory neurons of the different regions to separate variables.\n",
    "        topology_DG_CA3_inh = inhibitory_positions['DG_CA3']\n",
    "        topology_CA1_inh = inhibitory_positions['CA1']\n",
    "        topology_Sub_inh = inhibitory_positions['Sub']\n",
    "        topology_EC_inh = inhibitory_positions['EC']\n",
    "\n",
    "        # Adding all the topologies of the neurons to a list.\n",
    "        topologies = [topology_DG_CA3_exc, topology_CA1_exc, topology_Sub_exc, topology_EC_exc, topology_DG_CA3_inh, topology_CA1_inh, topology_Sub_inh, topology_EC_inh] \n",
    "        topology_names = ['DG_CA3_exc', 'CA1_exc', 'Sub_exc', 'EC_exc', 'DG_CA3_inh', 'CA1_inh', 'Sub_inh', 'EC_inh']\n",
    "\n",
    "        # Updating the 'current_variables' by adding the 'region_data' and 'region_geometrics'.\n",
    "        current_variables['region_data'] = region_data\n",
    "        current_variables['region_geometrics'] = region_geometrics\n",
    "\n",
    "        # Plotting all the hippocampal regions/topologies in a single 3D plot.\n",
    "        plot_all_hippocampal_topologies(topologies, topology_names, run_id)\n",
    "\n",
    "\n",
    "        ############################################\n",
    "        ########  Setting up Stimulus Mask  ########\n",
    "        ############################################\n",
    "        # Defining which topologies should be considered for the creation of the stimulus mask according to the stimulus regions.\n",
    "        topology_exc_stimulus = [[],[],[]]\n",
    "        for stimulus_region in current_variables['stimulus_regions']:\n",
    "            for i, (sublist1, sublist2) in enumerate(zip_longest(topology_exc_stimulus, excitatory_positions[stimulus_region], fillvalue=[])):\n",
    "                topology_exc_stimulus[i].extend(sublist2)\n",
    "\n",
    "        # If the shape of the stimulus mask is set to 'all', then there is no need to check the mask first.\n",
    "        if current_variables['shape_stimulus_mask'] == \"all\":\n",
    "            \n",
    "            ##########################################\n",
    "            ########  Creating Stimulus Mask  ########\n",
    "            ##########################################\n",
    "            stimulus_mask_exc = create_all_mask(topology_exc_stimulus)\n",
    "        \n",
    "        elif current_variables['shape_stimulus_mask'] == \"perc_of_all\":\n",
    "\n",
    "            ##########################################\n",
    "            ########  Creating Stimulus Mask  ########\n",
    "            ##########################################\n",
    "            stimulus_mask_exc = create_prec_of_all_mask(topology_exc_stimulus, current_variables['stimulus_mask_all_perc'])\n",
    "            \n",
    "        else:\n",
    "            # Checking whether the stimulus mask with the provided coordinate center and radius can be applied to the list of regions by calling the function 'checking_mask()'.\n",
    "            coord_of_stimulus, stimulus_radius_or_edge_length = checking_mask(current_variables['shape_stimulus_mask'], current_variables['stimulus_regions'], current_variables['stimulus_center_coordinates'], current_variables['stimulus_radius_or_edge_length'], current_variables['region_names'], region_geometrics)\n",
    "            \n",
    "            # Setting the overall geometry settings of the stimulus mask which includes both the middle point as well as the radius.\n",
    "            stimulus_geometry_settings = [coord_of_stimulus, stimulus_radius_or_edge_length]\n",
    "            \n",
    "            ##########################################\n",
    "            ########  Creating Stimulus Mask  ########\n",
    "            ##########################################\n",
    "            # Creating the stimulus mask for the defined 'topology_exc_stimulus' with as shape the 'current_variables['shape_stimulus_mask']'.\n",
    "            if current_variables['shape_stimulus_mask'] == \"spherical\":\n",
    "                stimulus_mask_exc = create_spherical_mask(topology_exc_stimulus, stimulus_geometry_settings)\n",
    "            elif current_variables['shape_stimulus_mask'] == \"cubical\":\n",
    "                stimulus_mask_exc = create_cubical_mask(topology_exc_stimulus, stimulus_geometry_settings)\n",
    "\n",
    "       \n",
    "        ############################################\n",
    "        ########  Setting up Electrode  ############\n",
    "        ############################################\n",
    "        # Adding the coordinates of the electrode to the 'variables' and 'current_variables'.\n",
    "        # variables['coord_of_electrode'] = populate_electrode_positions(variables)\n",
    "        # current_variables['coord_of_electrode'] = populate_electrode_positions(current_variables)\n",
    "\n",
    "\n",
    "        #############################################\n",
    "        ########  Setting up Treatment Mask  ########\n",
    "        #############################################\n",
    "        # Defining which topologies should be considered for the creation of the treatment mask according to the treatment regions.\n",
    "        topology_exc_treatment = [[],[],[]]\n",
    "        topology_inh_treatment = [[],[],[]]\n",
    "        for treatment_region in current_variables['treatment_regions']:\n",
    "            for i, (sublist1, sublist2) in enumerate(zip_longest(topology_exc_treatment, excitatory_positions[treatment_region], fillvalue=[])):\n",
    "                topology_exc_treatment[i].extend(sublist2)\n",
    "            for i, (sublist1, sublist2) in enumerate(zip_longest(topology_inh_treatment, inhibitory_positions[treatment_region], fillvalue=[])):\n",
    "                topology_inh_treatment[i].extend(sublist2)\n",
    "\n",
    "        # If the shape of the treatment mask is set to 'all', then there is no need to check the mask first.\n",
    "        if current_variables['shape_treatment_mask'] == \"all\":\n",
    "\n",
    "            ###########################################\n",
    "            ########  Creating Treatment Mask  ########\n",
    "            ###########################################\n",
    "            treatment_mask_exc = create_all_mask(topology_exc_treatment)\n",
    "            treatment_mask_inh = create_all_mask(topology_inh_treatment)\n",
    "\n",
    "        elif current_variables['shape_treatment_mask'] == \"perc_of_all\":\n",
    "\n",
    "            ###########################################\n",
    "            ########  Creating Treatment Mask  ########\n",
    "            ###########################################\n",
    "            treatment_mask_exc = create_prec_of_all_mask(topology_exc_treatment, current_variables['treatment_mask_all_perc'])\n",
    "            treatment_mask_inh = create_prec_of_all_mask(topology_inh_treatment, current_variables['treatment_mask_all_perc'])\n",
    "            \n",
    "        else:\n",
    "            # Checking whether the treatment mask with the provided coordinate center and radius can be applied to the list of regions by calling the function 'checking_treatment_mask()'.\n",
    "            coord_of_treatment, treatment_radius_or_edge_length = checking_treatment_mask(current_variables['shape_treatment_mask'], current_variables['treatment_regions'], current_variables['treatment_center_coordinates'], current_variables['treatment_radius_or_edge_length'], current_variables['region_names'], current_variables['distance_between_masks'], coord_of_stimulus, region_geometrics)\n",
    "            \n",
    "            # Setting the overall geometry settings of the treatment mask which includes both the middle point as well as the radius.\n",
    "            treatment_geometry_settings = [coord_of_treatment, treatment_radius_or_edge_length]\n",
    "            \n",
    "            ###########################################\n",
    "            ########  Creating Treatment Mask  ########\n",
    "            ###########################################\n",
    "            # Creating the treatment mask for the defined 'topology_exc_treatment' with as shape the 'current_variables['shape_treatment_mask']'.\n",
    "            if current_variables['shape_treatment_mask'] == \"spherical\":\n",
    "                treatment_mask_exc = create_spherical_mask(topology_exc_treatment, treatment_geometry_settings)\n",
    "                treatment_mask_inh = create_spherical_mask(topology_inh_treatment, treatment_geometry_settings)\n",
    "            elif current_variables['shape_treatment_mask'] == \"cubical\":\n",
    "                treatment_mask_exc = create_cubical_mask(topology_exc_treatment, treatment_geometry_settings)\n",
    "                treatment_mask_inh = create_cubical_mask(topology_inh_treatment, treatment_geometry_settings)\n",
    "\n",
    "        treatment_masks = [treatment_mask_exc, treatment_mask_inh]\n",
    "\n",
    "        # Plotting the stimulus and treatment masks in a 3D plot which also features all hippocampal topologies.\n",
    "        plotting_masks(topologies, topology_names, [current_variables['topology_names_stimulus'], current_variables['topology_names_treatment']], [stimulus_mask_exc, treatment_masks], run_id)\n",
    "\n",
    "    \n",
    "    \n",
    "        ########################################\n",
    "        ########  Initializing Network  ########\n",
    "        ########################################\n",
    "        # Instantiating the network and setting up the monitors.\n",
    "        net, synapses, monitors = prepare_network(topologies, stimulus_mask_exc, treatment_masks, current_variables)\n",
    "        popmon_DG_CA3_exc, popmon_CA1_exc, popmon_Sub_exc, popmon_EC_exc, popmon_DG_CA3_inh, popmon_CA1_inh, popmon_Sub_inh, popmon_EC_inh, Mlfp, statemon_DG_CA3_exc, statemon_CA1_exc, statemon_Sub_exc, statemon_EC_exc, statemon_DG_CA3_inh, statemon_CA1_inh, statemon_Sub_inh, statemon_EC_inh = monitors\n",
    "        \n",
    "        # Writing the network statistics to a file.\n",
    "        #write_network_statistics(synapses, current_variables['N'], run_id)\n",
    "\n",
    "        # Running the simulation with the dynamic objects created above.\n",
    "        run_granular_simulation(net, current_variables, treatment_settings, monitors)\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        ########  Saving Firing Rate Data  ########\n",
    "        ###########################################\n",
    "        # Saving the firing rate data for every single region.\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_DG_CA3_exc.txt', popmon_DG_CA3_exc.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_DG_CA3_inh.txt', popmon_DG_CA3_inh.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_CA1_exc.txt', popmon_CA1_exc.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_CA1_inh.txt', popmon_CA1_inh.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_Sub_exc.txt', popmon_Sub_exc.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_Sub_inh.txt', popmon_Sub_inh.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_EC_exc.txt', popmon_EC_exc.rate)\n",
    "        np.savetxt(f'./results/{run_id}/firing_rate_EC_inh.txt', popmon_EC_inh.rate)\n",
    "\n",
    "        # Plotting the firing rate data for both the excitatory and inhibitory neurons of the DG_CA3 region.\n",
    "        plt.plot(popmon_DG_CA3_exc.t, popmon_DG_CA3_exc.rate, label='DG_CA3_exc')\n",
    "        plt.plot(popmon_DG_CA3_inh.t, popmon_DG_CA3_inh.rate, label='DG_CA3_inh')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'./results/{run_id}/firing_rate_DG_CA3.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Plotting the firing rate data for both the excitatory and inhibitory neurons of the CA1 region.\n",
    "        plt.plot(popmon_CA1_exc.t, popmon_CA1_exc.rate, label='CA1_exc')\n",
    "        plt.plot(popmon_CA1_inh.t, popmon_CA1_inh.rate, label='CA1_inh')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'./results/{run_id}/firing_rate_CA1.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Plotting the firing rate data for both the excitatory and inhibitory neurons of the Sub region.\n",
    "        plt.plot(popmon_Sub_exc.t, popmon_Sub_exc.rate, label='Sub_exc')\n",
    "        plt.plot(popmon_Sub_inh.t, popmon_Sub_inh.rate, label='Sub_inh')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'./results/{run_id}/firing_rate_Sub.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Plotting the firing rate data for both the excitatory and inhibitory neurons of the EC region.\n",
    "        plt.plot(popmon_EC_exc.t, popmon_EC_exc.rate, label='EC_exc')\n",
    "        plt.plot(popmon_EC_inh.t, popmon_EC_inh.rate, label='EC_inh')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'./results/{run_id}/firing_rate_EC.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        #####################################\n",
    "        ########  Saving Noise Data  ########\n",
    "        #####################################\n",
    "        # Plotting and saving the noise for the excitatory and inhibitory neurons of the DG_CA3 region.\n",
    "        plt.plot(statemon_DG_CA3_exc.t, statemon_DG_CA3_exc.I_noise[4]/nA, label='exc')\n",
    "        plt.savefig(f'./results/{run_id}/noise_DG_CA3_exc.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.plot(statemon_DG_CA3_inh.t, statemon_DG_CA3_inh.I_noise[4]/nA, label='inh')\n",
    "        plt.savefig(f'./results/{run_id}/noise_DG_CA3_inh.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Plotting and saving the noise for the excitatory and inhibitory neurons of the CA1 region.\n",
    "        plt.plot(statemon_CA1_exc.t, statemon_CA1_exc.I_noise[4]/nA, label='exc')\n",
    "        plt.savefig(f'./results/{run_id}/noise_CA1_exc.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.plot(statemon_CA1_inh.t, statemon_CA1_inh.I_noise[4]/nA, label='inh')\n",
    "        plt.savefig(f'./results/{run_id}/noise_CA1_inh.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Plotting and saving the noise for the excitatory and inhibitory neurons of the Sub region.\n",
    "        plt.plot(statemon_Sub_exc.t, statemon_Sub_exc.I_noise[4]/nA, label='exc')\n",
    "        plt.savefig(f'./results/{run_id}/noise_Sub_exc.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.plot(statemon_Sub_inh.t, statemon_Sub_inh.I_noise[4]/nA, label='inh')\n",
    "        plt.savefig(f'./results/{run_id}/noise_Sub_inh.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Plotting and saving the noise for the excitatory and inhibitory neurons of the EC region.\n",
    "        plt.plot(statemon_EC_exc.t, statemon_EC_exc.I_noise[4]/nA, label='exc')\n",
    "        plt.savefig(f'./results/{run_id}/noise_EC_exc.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.plot(statemon_EC_inh.t, statemon_EC_inh.I_noise[4]/nA, label='inh')\n",
    "        plt.savefig(f'./results/{run_id}/noise_EC_inh.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        ###################################\n",
    "        ########  Saving LFP Data  ########\n",
    "        ###################################\n",
    "        # Plotting and saving the recorded LFP voltage values in millivolts from the 'Mlfp' monitor. \n",
    "        np.savetxt(f'./results/{run_id}/voltage_LFP.txt', Mlfp.v[0]/mV)\n",
    "        plot(Mlfp.t/ms, Mlfp.v[0]/mV)\n",
    "        plt.savefig(f'./results/{run_id}/voltage_LFP.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f620dff-7178-4719-802d-234e01d7ade9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cca24-3e0f-4117-8319-1da3cb93a36c",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Simulation Variables - Simulation 1  - Different Regions </h2>\n",
    "\n",
    "Stimulus: DG_CA3, CA1\n",
    "\n",
    "Treatment: all regions (DG_CA3, CA1, Sub, EC)\n",
    "\n",
    "total runs: 8 (4 each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d31ab2-0292-48fa-bc64-28c8b956bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########  Simulation Variables  ########\n",
    "########################################\n",
    "\n",
    "# Setting the number of times the simulation will be performed.\n",
    "copy_times = 4\n",
    "\n",
    "\n",
    "# Defining the volumes, neuron densities, and excitatory to inhibitory ratios of the regions.\n",
    "region_volumes = {\"DG_CA3\": 128.85, \n",
    "                  \"CA1\": 177.5, \n",
    "                  \"Sub\": 91.55,\n",
    "                  \"EC\": 88.25}\n",
    "DG_neuron_density = 87100\n",
    "CA3_neuron_density = 15100\n",
    "region_densities_dict = {\"DG_CA3\": (DG_neuron_density + CA3_neuron_density) / 2,\n",
    "                         \"CA1\": 7900, \n",
    "                         \"Sub\": 21500,\n",
    "                         \"EC\": 27400}\n",
    "region_excitatory_ratios_dict = {\"DG_CA3\": 0.8, \n",
    "                                 \"CA1\": 0.8, \n",
    "                                 \"Sub\": 0.8,\n",
    "                                 \"EC\": 0.8}\n",
    "\n",
    "# Defining the connection probabilities between neurons from different regions.\n",
    "DG_proportion = DG_neuron_density / (DG_neuron_density + CA3_neuron_density)\n",
    "CA3_proportion = CA3_neuron_density / (DG_neuron_density + CA3_neuron_density)\n",
    "probabilities_between_regions = {\"DG_CA3_to_CA1\": (DG_proportion * 0) + (CA3_proportion * 0.1),\n",
    "                                 \"CA1_to_Sub\": 0.55, \n",
    "                                 \"CA1_to_EC\": 0.1,\n",
    "                                 \"EC_to_DG_CA3\": (DG_proportion * 0.1) + (CA3_proportion * 0.06),\n",
    "                                 \"EC_to_CA1\": 0.06}\n",
    "\n",
    "# Defining the connection probabilities between neurons from the same region.\n",
    "probabilities_within_regions = {\"DG_CA3_e2e\": (DG_proportion * 0) + (CA3_proportion * 0.56),\n",
    "                                \"DG_CA3_e2i\": (DG_proportion * 0.06) + (CA3_proportion * 0.75),\n",
    "                                \"DG_CA3_i2e\": (DG_proportion * 0.14) + (CA3_proportion * 0.75),\n",
    "                                \"CA1_e2i\": 0.28,\n",
    "                                \"CA1_i2e\": 0.3,\n",
    "                                \"CA1_i2i\": 0.7,\n",
    "                                \"Sub_e2e\": 0.0523,\n",
    "                                \"Sub_e2i\": 0.185,\n",
    "                                \"Sub_i2e\": 0.405,\n",
    "                                \"Sub_i2i\": 0.23,\n",
    "                                \"EC_e2i\": 0.37,\n",
    "                                \"EC_i2e\": 0.54}\n",
    "                            \n",
    "# Defining the vocabulary of variables.\n",
    "variables = {\n",
    "    \n",
    "    # Defining the simulation settings.\n",
    "    # EMMA\n",
    "    \"run_id\": ['Sim1 stimulusDG_CA3 treatmentDG_CA3', 'Sim1 stimulusDG_CA3 treatmentCA1', 'Sim1 stimulusDG_CA3 treatmentSub', 'Sim1 stimulusDG_CA3 treatmentEC'],\n",
    "    \"stimulus_regions\": [['DG_CA3']]*copy_times,\n",
    "    \"topology_names_stimulus\": [['DG_CA3_exc']]*copy_times,\n",
    "    \"stimulus_center_coordinates\": [[0.35, 0.45, 0.25]]*copy_times,\n",
    "    \"stimulus_radius_or_edge_length\": [0.1]*copy_times,\n",
    "    \"shape_stimulus_mask\": ['spherical']*copy_times, # 'spherical', 'cubical', 'all'\n",
    "\n",
    "    \n",
    "    # REGINA\n",
    "    # \"run_id\": ['Sim1 stimulusCA1 treatmentDG_CA3', 'Sim1 stimulusCA1 treatmentCA1', 'Sim1 stimulusCA1 treatmentSub', 'Sim1 stimulusCA1 treatmentEC'],\n",
    "    # \"stimulus_regions\": [['CA1']]*copy_times,\n",
    "    # \"topology_names_stimulus\": [['CA1_exc']]*copy_times,\n",
    "    # \"stimulus_center_coordinates\": [[0.125,0.3, 0.25]]*copy_times,\n",
    "    # \"stimulus_radius_or_edge_length\": [1]*copy_times,\n",
    "    # \"shape_stimulus_mask\": ['spherical']*copy_times, # 'spherical', 'cubical', 'all'\n",
    "\n",
    "\n",
    "    \"treatment_regions\": [['DG_CA3'], ['CA1'], ['Sub'], ['EC']],\n",
    "    \"topology_names_treatment\": [['DG_CA3_exc', 'DG_CA3_inh'], ['CA1_exc', 'CA1_inh'], ['Sub_exc', 'Sub_inh'], ['EC_exc', 'EC_inh']],\n",
    "    \"treatment_center_coordinates\": [[0.65, 0.45, 0.25], [0.125, 0.3, 0.25], [0.88, 0.795, 0.25], [1.495, 0.625, 0.25]],\n",
    "    \"treatment_radius_or_edge_length\": [0.1]*copy_times,\n",
    "    \"shape_treatment_mask\": ['spherical']*copy_times, # 'spherical', 'cubical', 'all', 'perc_of_all'\n",
    "    \n",
    "    \"duration\": [4000*ms]*copy_times,\n",
    "    \"copy_times\": [copy_times]*copy_times,\n",
    "\n",
    "    # Defining the total number of neurons of the model.\n",
    "    \"N\": [17000]*copy_times,\n",
    "\n",
    "    # Defining the bounds used in the random topology model.\n",
    "    \"bounds\": [[0.6, 0.6, 0.6]]*copy_times,\n",
    "    \n",
    "    # Defining the number of neurons per mm^3 and the excitatory ratio for each of the regions.\n",
    "    \"region_names\": [['DG_CA3', 'CA1', 'Sub', 'EC']]*copy_times,\n",
    "    \"region_volumes\": [dict(region_volumes)]*copy_times,\n",
    "    \"region_densities\": [dict(region_densities_dict)]*copy_times,\n",
    "    \"excitatory_ratios\": [dict(region_excitatory_ratios_dict)]*copy_times,\n",
    "\n",
    "    # Defining the potassium equilibrium potential for both the excitatory and inhibitory neurons.\n",
    "    # - Healthy mode: Eke_baseline = -90mV\n",
    "    # - Epileptic mode: Eke_baseline = -84mV\n",
    "    \"Eke_baseline\": [-84*mV]*copy_times, \n",
    "    \"Eki_baseline\": [-90*mV]*copy_times,\n",
    "\n",
    "    # Defining the noise affecting the excitatory and inhibitory neurons.\n",
    "    \"noise_exc\": [[0.07, 0.075]*nA]*copy_times, # OLD: [0.1045, 0.104]\n",
    "    \"noise_inh\": [[0.05, 0.08]*nA]*copy_times,\n",
    "\n",
    "    # Defining the base probabilities of connections between neurons from different regions:\n",
    "    # - p_e2e => Probability of an excitatory to excitatory neuron (synapse) connection.\n",
    "    # - p_e2i => Probability of an excitatory to inhibitory neuron (synapse) connection.\n",
    "    # - p_i2e => Probability of an inhibitory to excitatory neuron (synapse) connection.\n",
    "    # - p_i2i => Probability of an inhibitory to inhibitory neuron (synapse) connection.\n",
    "    # Normal ranges from 0.7-0.75, to activate sprouting increase the normal by 0.5\n",
    "    # This will increase the average number of excitatory connections by 500.\n",
    "    #\"p\": [[0.75, 0.35, 0.35, 0.0]]*copy_times, \n",
    "\n",
    "    # Defining the connection probabilities between neurons from different and the same regions.\n",
    "    \"probabilities_between_regions\": [dict(probabilities_between_regions)]*copy_times,\n",
    "    \"probabilities_within_regions\": [dict(probabilities_within_regions)]*copy_times,\n",
    "\n",
    "    # Defining from which file the stimulus originates.\n",
    "    \"input_signal_file\": ['sigmoid-1.0.txt']*copy_times, \n",
    "\n",
    "    ## Defining which parameters can be tweaked for the stimulus mask:\n",
    "    # - stimulus regions: The regions that will feature the stimulus mask.\n",
    "    # - stimulus center coordinates: The center coordinates of the stimulus mask.\n",
    "    # - stimulus radius/edge length: The radius/edge length of the stimulus mask.\n",
    "    # - stimulus shape: The shape of the stimulus mask.\n",
    "    \"stimulus_mask_all_perc\": [50]*copy_times,\n",
    "    \n",
    "    ## Defining which parameters are needed for the creation of the treatment mask:\n",
    "    # - treatment regions: The regions that will feature the treatment mask.\n",
    "    # - stimulus center coordinates: The center coordinates of the stimulus mask.\n",
    "    # - stimulus radius/edge length: The radius/edge length of the stimulus mask.\n",
    "    # - treatment shape: The shape of the treatment mask.\n",
    "    \"treatment_mask_all_perc\": [50]*copy_times,\n",
    "    \"distance_between_masks\": [0]*copy_times,\n",
    "\n",
    "    ## Defining other parameters that can be tweaked for treatment:\n",
    "    # - firing rate threshold: Rate at which the treatment should be activated.\n",
    "    # - device sensitivity: Frequency with which is checked if the firing rate is above the threshold.\n",
    "    # - Eke treatment: The potassium equilibrium potential for the excitatory neurons once treatment is activated.\n",
    "    # - Eke treatment: The potassium equilibrium potential for the inhibitory neurons once treatment is activated (unchanged from untreated).\n",
    "    \"firing_rate_threshold\": [5*Hz]*copy_times,\n",
    "    \"device_sensitivity\": [8*ms]*copy_times,\n",
    "    \"Eke_treatment\": [-100*mV]*copy_times,\n",
    "    \"Eki_treatment\": [-90*mV]*copy_times,\n",
    "\n",
    "    # Defining which region should feature the LFP electrode.\n",
    "    \"LFP_electrode_region\": ['DG_CA3']*copy_times\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a1c98-2e2a-43c9-aef3-0741055bbcd0",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe492a7-cfc9-4d92-90e6-e147318e391a",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Simulation Variables - Simulation 2  - Change Stimulus and Treatment Locations within the 2 Best Regions </h2>\n",
    "\n",
    "Stimulus: 3 different locations in the best region (A,B,C)\n",
    "\n",
    "Treatment: 3 different locations in the best region (A,B,C)\n",
    "\n",
    "total runs: 9 (5 for one, 4 for the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b32ec0-40f0-46bc-8311-97fa4bba0596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50a6a9a8-2f4f-4091-8fb1-251c4beaa5d2",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b3b67e-3308-4496-bbb4-ac96bff2e8b7",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Simulation Variables - Simulation 3  - Change Stimulus and Treatment Size and Shape within the 2 Best Regions </h2>\n",
    "\n",
    "Stimulus: 4 different sizes and shapes\n",
    "    1. normal size circle (size 1)\n",
    "    2. big size circle (size 2)\n",
    "    3. whole region\n",
    "    4. cubic shape\n",
    "\n",
    "Treatment: 4 different sizes and shapes\n",
    "    1. normal size circle (size 1)\n",
    "    2. big size circle (size 2)\n",
    "    3. whole region\n",
    "    4. cubic shape\n",
    "\n",
    "total runs: 7\n",
    "\n",
    "    1. stimulus: normal size circle vs. treatment: normal size circle\n",
    "    \n",
    "    2. stimulus: normal size circle vs. treatment: big size circle\n",
    "    \n",
    "    3. stimulus: normal size circle vs. treatment: whole region\n",
    "    \n",
    "    4. stimulus: normal size circle vs. treatment: cubic shape\n",
    "    \n",
    "    5. stimulus: big size circle vs. treatment: normal size circle\n",
    "    \n",
    "    6. stimulus: whole region vs. treatment: normal size circle\n",
    "    \n",
    "    7. stimulus: cubic shape vs. treatment: normal size circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c970d-7330-4c65-9959-c56940f7a4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26f15a62-f4e6-4b18-b0a1-14dc2635cf80",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11cb427-d340-4fc2-8c6a-5ac41b7937fe",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Running the Simulation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acd976-f109-41f2-8f8b-c934777e73b5",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 20px;\">Simulation 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b7623-808c-4847-b451-7014f214d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the simulation with the variables for simulation 1.\n",
    "run_model_loop(variables_sim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ddc669-ad23-49eb-8d58-f61be0778631",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ce960-f022-449f-83e2-b94dabe0e2f3",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 20px;\">Simulation 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9a8d6-24d7-428a-b1ad-acecc94c7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the simulation with the variables for simulation 2.\n",
    "run_model_loop(variables_sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f26e7-dc17-4faf-9c02-fd84caa131e9",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4562930-c124-42a1-96bc-5abe5c51acf7",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 20px;\">Simulation 3</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23914d-5d8a-4e7e-8fde-de38930c514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the simulation with the variables for simulation 3.\n",
    "run_model_loop(variables_sim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a460e7-2078-40bf-950a-0fc9a09e0d10",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85fb08-7a67-4137-a293-180c81894f17",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 60px;\">BASIC SIMULATION CODE</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172ae1d-5156-47c1-90d5-9711bb7d9e96",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Simulation Variables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c3fd703-e6b4-40ac-805d-ab2cc4bd5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########  Simulation Variables  ########\n",
    "########################################\n",
    "\n",
    "# Setting the number of times the simulation will be performed.\n",
    "copy_times = 5\n",
    "\n",
    "\n",
    "# Defining the volumes, neuron densities, and excitatory to inhibitory ratios of the regions.\n",
    "region_volumes = {\"DG_CA3\": 128.85, \n",
    "                  \"CA1\": 177.5, \n",
    "                  \"Sub\": 91.55,\n",
    "                  \"EC\": 88.25}\n",
    "region_densities_dict = {\"DG_CA3\": 87100, # Maybe change this one.\n",
    "                         \"CA1\": 7900, \n",
    "                         \"Sub\": 21500,\n",
    "                         \"EC\": 27400}\n",
    "region_excitatory_ratios_dict = {\"DG_CA3\": 0.8, \n",
    "                                 \"CA1\": 0.8, \n",
    "                                 \"Sub\": 0.8,\n",
    "                                 \"EC\": 0.8}\n",
    "\n",
    "# Defining the connection probabilities between neurons from different regions.\n",
    "DG_neuron_density = 87100\n",
    "CA3_neuron_density = 15100\n",
    "DG_proportion = DG_neuron_density / (DG_neuron_density + CA3_neuron_density)\n",
    "CA3_proportion = CA3_neuron_density / (DG_neuron_density + CA3_neuron_density)\n",
    "probabilities_between_regions = {\"DG_CA3_to_CA1\": (DG_proportion * 0) + (CA3_proportion * 0.1),\n",
    "                                 \"CA1_to_Sub\": 0.55, # Maybe change this one.\n",
    "                                 \"CA1_to_EC\": 0.1,\n",
    "                                 \"EC_to_DG_CA3\": (DG_proportion * 0.1) + (CA3_proportion * 0.06),\n",
    "                                 \"EC_to_CA1\": 0.06}\n",
    "\n",
    "# Defining the connection probabilities between neurons from the same region.\n",
    "probabilities_within_regions = {\"DG_CA3_e2e\": (DG_proportion * 0) + (CA3_proportion * 0.56),\n",
    "                                \"DG_CA3_e2i\": (DG_proportion * 0.06) + (CA3_proportion * 0.75),\n",
    "                                \"DG_CA3_i2e\": (DG_proportion * 0.14) + (CA3_proportion * 0.75),\n",
    "                                \"CA1_e2i\": 0.28,\n",
    "                                \"CA1_i2e\": 0.3,\n",
    "                                \"CA1_i2i\": 0.7,\n",
    "                                \"Sub_e2e\": 0.0523,\n",
    "                                \"Sub_e2i\": 0.185,\n",
    "                                \"Sub_i2e\": 0.405,\n",
    "                                \"Sub_i2i\": 0.23,\n",
    "                                \"EC_e2i\": 0.37,\n",
    "                                \"EC_i2e\": 0.54}\n",
    "                            \n",
    "# Defining the vocabulary of variables.\n",
    "variables = {\n",
    "    \n",
    "    # Defining the simulation settings.\n",
    "    \"run_id\": ['Results 1', 'Results 2', 'Results 3', 'Results 4', 'Results 5'],\n",
    "    \"duration\": [4000*ms]*copy_times,\n",
    "    \"copy_times\": [copy_times]*copy_times,\n",
    "\n",
    "    # Defining the total number of neurons of the model.\n",
    "    \"N\": [17000]*copy_times,\n",
    "\n",
    "    # Defining the bounds used in the random topology model.\n",
    "    \"bounds\": [[0.6, 0.6, 0.6]]*copy_times,\n",
    "    \n",
    "    # Defining the number of neurons per mm^3 and the excitatory ratio for each of the regions.\n",
    "    \"region_names\": [['DG_CA3', 'CA1', 'Sub', 'EC']]*copy_times,\n",
    "    \"region_volumes\": [dict(region_volumes)]*copy_times,\n",
    "    \"region_densities\": [dict(region_densities_dict)]*copy_times,\n",
    "    \"excitatory_ratios\": [dict(region_excitatory_ratios_dict)]*copy_times,\n",
    "\n",
    "    # Defining the potassium equilibrium potential for both the excitatory and inhibitory neurons.\n",
    "    # - Healthy mode: Eke_baseline = -90mV\n",
    "    # - Epileptic mode: Eke_baseline = -84mV\n",
    "    \"Eke_baseline\": [-84*mV]*copy_times, \n",
    "    \"Eki_baseline\": [-90*mV]*copy_times,\n",
    "\n",
    "    # Defining the noise affecting the excitatory and inhibitory neurons.\n",
    "    \"noise_exc\": [[0.07, 0.075]*nA]*copy_times, # OLD: [0.1045, 0.104]\n",
    "    \"noise_inh\": [[0.05, 0.08]*nA]*copy_times,\n",
    "\n",
    "    # Defining the base probabilities of connections between neurons from different regions:\n",
    "    # - p_e2e => Probability of an excitatory to excitatory neuron (synapse) connection.\n",
    "    # - p_e2i => Probability of an excitatory to inhibitory neuron (synapse) connection.\n",
    "    # - p_i2e => Probability of an inhibitory to excitatory neuron (synapse) connection.\n",
    "    # - p_i2i => Probability of an inhibitory to inhibitory neuron (synapse) connection.\n",
    "    # Normal ranges from 0.7-0.75, to activate sprouting increase the normal by 0.5\n",
    "    # This will increase the average number of excitatory connections by 500.\n",
    "    #\"p\": [[0.75, 0.35, 0.35, 0.0]]*copy_times, \n",
    "\n",
    "    # Defining the connection probabilities between neurons from different and the same regions.\n",
    "    \"probabilities_between_regions\": [dict(probabilities_between_regions)]*copy_times,\n",
    "    \"probabilities_within_regions\": [dict(probabilities_within_regions)]*copy_times,\n",
    "\n",
    "    # Defining from which file the stimulus originates.\n",
    "    \"input_signal_file\": ['sigmoid-1.0.txt']*copy_times, \n",
    "\n",
    "    ## Defining which parameters can be tweaked for the stimulus mask:\n",
    "    # - stimulus regions: The regions that will feature the stimulus mask.\n",
    "    # - stimulus center coordinates: The center coordinates of the stimulus mask.\n",
    "    # - stimulus radius/edge length: The radius/edge length of the stimulus mask.\n",
    "    # - stimulus shape: The shape of the stimulus mask.\n",
    "    \"stimulus_regions\": [['DG_CA3']]*copy_times,\n",
    "    \"topology_names_stimulus\": [['DG_CA3_exc']]*copy_times,\n",
    "    \"stimulus_center_coordinates\": [[0.5, 0.35, 0.25]]*copy_times,\n",
    "    \"stimulus_radius_or_edge_length\": [0.2]*copy_times,\n",
    "    \"shape_stimulus_mask\": ['spherical']*copy_times, # 'spherical', 'cubical', 'all', 'perc_of_all'\n",
    "    \"stimulus_mask_all_perc\": [50]*copy_times,\n",
    "    \n",
    "    ## Defining which parameters are needed for the creation of the treatment mask:\n",
    "    # - treatment regions: The regions that will feature the treatment mask.\n",
    "    # - stimulus center coordinates: The center coordinates of the stimulus mask.\n",
    "    # - stimulus radius/edge length: The radius/edge length of the stimulus mask.\n",
    "    # - treatment shape: The shape of the treatment mask.\n",
    "    \"treatment_regions\": [['Sub']]*copy_times,\n",
    "    \"topology_names_treatment\": [['Sub_exc', 'Sub_inh']]*copy_times,\n",
    "    \"treatment_center_coordinates\": [[1.18, 0.85, 0.25]]*copy_times,\n",
    "    \"treatment_radius_or_edge_length\": [0.11]*copy_times,\n",
    "    \"shape_treatment_mask\": ['spherical']*copy_times, # 'spherical', 'cubical', 'all', 'perc_of_all'\n",
    "    \"treatment_mask_all_perc\": [50]*copy_times,\n",
    "    \"distance_between_masks\": [0]*copy_times,\n",
    "\n",
    "    ## Defining other parameters that can be tweaked for treatment:\n",
    "    # - firing rate threshold: Rate at which the treatment should be activated.\n",
    "    # - device sensitivity: Frequency with which is checked if the firing rate is above the threshold.\n",
    "    # - Eke treatment: The potassium equilibrium potential for the excitatory neurons once treatment is activated.\n",
    "    # - Eke treatment: The potassium equilibrium potential for the inhibitory neurons once treatment is activated (unchanged from untreated).\n",
    "    \"firing_rate_threshold\": [5*Hz]*copy_times,\n",
    "    \"device_sensitivity\": [8*ms]*copy_times,\n",
    "    \"Eke_treatment\": [-100*mV]*copy_times,\n",
    "    \"Eki_treatment\": [-90*mV]*copy_times,\n",
    "\n",
    "    # Defining which region should feature the LFP electrode.\n",
    "    \"LFP_electrode_region\": ['DG_CA3']*copy_times\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411d6b-3854-4032-b1eb-e387906af638",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643c399-9a7c-4e4e-8a53-afee09595e84",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 40px;\">Running the Simulation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5642155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70. 75.] pA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    Cannot use Cython, a test compilation failed: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/ (DistutilsPlatformError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Network at time t=0. s, containing objects: <PopulationRateMonitor, recording inh_group_DG_CA3>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_Sub_e2e_pre'), <StateMonitor, recording ('v', 'I_stim', 'I_noise') from 'exc_group_EC'>, Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_Sub_e2e'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_EC_i2e_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_DG_CA3_i2i'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_DG_CA3_e2i_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_CA1_e2e'), <StateMonitor, recording ('v', 'I_noise') from 'inh_group_Sub'>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_EC_i2i_pre'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='inh_group_EC'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_EC_i2e'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_EC_i2e'), <PopulationRateMonitor, recording inh_group_CA1>, StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='exc_group_EC_stateupdater'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_Sub_e2i'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_DG_CA3_CA1_e2e'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='exc_group_CA1_stateupdater'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_EC_e2i'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_EC_e2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_DG_CA3_CA1_e2e_pre'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='inh_group_Sub_stateupdater'), <StateMonitor, recording ('v', 'I_stim', 'I_noise') from 'exc_group_CA1'>, Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='exc_group_CA1_spike_thresholder'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='inh_group_DG_CA3'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_Sub_i2e_pre'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='exc_group_CA1_subexpression_update'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_CA1_i2e_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_DG_CA3_i2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_Sub_i2e_pre'), <PopulationRateMonitor, recording inh_group_Sub>, Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='inh_group_Sub_spike_thresholder'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='exc_group_DG_CA3'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='inh_group_DG_CA3_stateupdater'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='exc_group_CA1'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='inh_group_Sub_subexpression_update'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_DG_CA3_i2e'), Resetter(clock=Clock(dt=1. * msecond, name='defaultclock'), when=resets, order=0, name='exc_group_DG_CA3_spike_resetter'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_DG_CA3_i2e_pre'), <StateMonitor, recording ('v', 'I_noise') from 'inh_group_DG_CA3'>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_EC_e2e_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_Sub_e2i'), <StateMonitor, recording ('v', 'I_noise') from 'inh_group_EC'>, NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='neurongroup'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_DG_CA3_CA1_i2e_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_Sub_e2e_pre'), <PopulationRateMonitor, recording exc_group_DG_CA3>, Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_DG_CA3_CA1_e2i'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='inh_group_EC_stateupdater'), <PopulationRateMonitor, recording inh_group_EC>, Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='exc_group_Sub_spike_thresholder'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_CA1_e2i_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_Sub_i2i'), Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='inh_group_DG_CA3_spike_thresholder'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_EC_e2e'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_Sub_i2i'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_24'), <PopulationRateMonitor, recording exc_group_CA1>, Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_CA1_i2i'), Resetter(clock=Clock(dt=1. * msecond, name='defaultclock'), when=resets, order=0, name='exc_group_Sub_spike_resetter'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_Sub_e2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_Sub_e2i_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_DG_CA3_e2i'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_CA1_e2i_pre'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='inh_group_DG_CA3_subexpression_update'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='exc_group_DG_CA3_subexpression_update'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_EC_i2e_pre'), <StateMonitor, recording ('v', 'I_stim', 'I_noise') from 'exc_group_Sub'>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_CA1_i2i_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_Sub_e2e'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_DG_CA3_e2e_pre'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='exc_group_Sub_subexpression_update'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_CA1_e2e_pre'), <StateMonitor, recording ['v'] from 'neurongroup'>, Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_CA1_i2i'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_DG_CA3_CA1_i2i'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='exc_group_Sub_stateupdater'), Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='exc_group_EC_spike_thresholder'), <PopulationRateMonitor, recording exc_group_Sub>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_DG_CA3_CA1_e2i_pre'), Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='inh_group_EC_spike_thresholder'), Resetter(clock=Clock(dt=1. * msecond, name='defaultclock'), when=resets, order=0, name='exc_group_EC_spike_resetter'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='inh_group_Sub'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='inh_group_EC_subexpression_update'), Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='exc_group_DG_CA3_spike_thresholder'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_EC_e2i'), <StateMonitor, recording ('v', 'I_noise') from 'inh_group_CA1'>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_Sub_i2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_CA1_i2i_pre'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_DG_CA3_e2e'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_DG_CA3_e2e'), SummedVariableUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=after_groups, order=-1, name='synapses_24_summed_variable_v_post'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='exc_group_Sub'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_DG_CA3_e2i_pre'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='exc_group_EC'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='exc_group_EC_subexpression_update'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_CA1_e2i'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_Sub_i2e'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='exc_group_DG_CA3_stateupdater'), NeuronGroup(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='inh_group_CA1'), StateUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=groups, order=0, name='inh_group_CA1_stateupdater'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_DG_CA3_e2i'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_EC_i2i'), <PopulationRateMonitor, recording exc_group_EC>, Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_CA1_Sub_i2e'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_CA1_i2e'), <StateMonitor, recording ('v', 'I_stim', 'I_noise') from 'exc_group_DG_CA3'>, SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_CA1_EC_e2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_CA1_i2e_pre'), Resetter(clock=Clock(dt=1. * msecond, name='defaultclock'), when=resets, order=0, name='exc_group_CA1_spike_resetter'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_EC_CA1_e2i'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_Sub_i2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_DG_CA3_CA1_i2i_pre'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_between_EC_DG_CA3_i2e_pre'), Thresholder(clock=Clock(dt=1. * msecond, name='defaultclock'), when=thresholds, order=0, name='inh_group_CA1_spike_thresholder'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_between_DG_CA3_CA1_i2e'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_CA1_i2e'), Synapses(clock=Clock(dt=1. * msecond, name='defaultclock'), when=start, order=0, name='synapses_within_DG_CA3_i2e'), SynapticPathway(clock=Clock(dt=1. * msecond, name='defaultclock'), when=synapses, order=-1, name='synapses_within_DG_CA3_e2e_pre'), SubexpressionUpdater(clock=Clock(dt=1. * msecond, name='defaultclock'), when=before_start, order=0, name='inh_group_CA1_subexpression_update')>\n",
      "#######################\n",
      "# Starting Simulation #\n",
      "#######################\n",
      "\n",
      "Treatment Parameters: time sensitivity 8. ms FR Threshold: 5. Hz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    The object 'synapses' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 160, in prepare_network\n",
      "    testing_S_CA1_EC_e2e_no_dist = Synapses(G_CA1_exc, G_EC_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_1' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 161, in prepare_network\n",
      "    testing_S_CA1_EC_e2e_dist = Synapses(G_CA1_exc, G_EC_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_2' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 166, in prepare_network\n",
      "    testing_S_CA1_EC_e2i_no_dist = Synapses(G_CA1_exc, G_EC_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_3' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 167, in prepare_network\n",
      "    testing_S_CA1_EC_e2i_dist = Synapses(G_CA1_exc, G_EC_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_4' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 172, in prepare_network\n",
      "    testing_S_CA1_EC_i2e_no_dist = Synapses(G_CA1_inh, G_EC_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_5' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 173, in prepare_network\n",
      "    testing_S_CA1_EC_i2e_dist = Synapses(G_CA1_inh, G_EC_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_6' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 178, in prepare_network\n",
      "    testing_S_CA1_EC_i2i_no_dist = Synapses(G_CA1_inh, G_EC_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_7' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 179, in prepare_network\n",
      "    testing_S_CA1_EC_i2i_dist = Synapses(G_CA1_inh, G_EC_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_8' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 201, in prepare_network\n",
      "    testing_S_EC_DG_CA3_e2e_no_dist = Synapses(G_EC_exc, G_DG_CA3_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_9' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 202, in prepare_network\n",
      "    testing_S_EC_DG_CA3_e2e_dist = Synapses(G_EC_exc, G_DG_CA3_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_10' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 207, in prepare_network\n",
      "    testing_S_EC_DG_CA3_e2i_no_dist = Synapses(G_EC_exc, G_DG_CA3_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_11' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 208, in prepare_network\n",
      "    testing_S_EC_DG_CA3_e2i_dist = Synapses(G_EC_exc, G_DG_CA3_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_12' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 213, in prepare_network\n",
      "    testing_S_EC_DG_CA3_i2e_no_dist = Synapses(G_EC_inh, G_DG_CA3_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_13' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 214, in prepare_network\n",
      "    testing_S_EC_DG_CA3_i2e_dist = Synapses(G_EC_inh, G_DG_CA3_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_14' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 219, in prepare_network\n",
      "    testing_S_EC_DG_CA3_i2i_no_dist = Synapses(G_EC_inh, G_DG_CA3_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_15' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 220, in prepare_network\n",
      "    testing_S_EC_DG_CA3_i2i_dist = Synapses(G_EC_inh, G_DG_CA3_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_16' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 242, in prepare_network\n",
      "    testing_S_EC_CA1_e2e_no_dist = Synapses(G_EC_exc, G_CA1_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_17' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 243, in prepare_network\n",
      "    testing_S_EC_CA1_e2e_dist = Synapses(G_EC_exc, G_CA1_exc, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_18' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 248, in prepare_network\n",
      "    testing_S_EC_CA1_e2i_no_dist = Synapses(G_EC_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_19' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 249, in prepare_network\n",
      "    testing_S_EC_CA1_e2i_dist = Synapses(G_EC_exc, G_CA1_inh, on_pre=\"he_post+=\"+str(gain)+\"*\"+str(g_max_e/siemens)+\"*siemens*glu_pre\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_20' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 254, in prepare_network\n",
      "    testing_S_EC_CA1_i2e_no_dist = Synapses(G_EC_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_21' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 255, in prepare_network\n",
      "    testing_S_EC_CA1_i2e_dist = Synapses(G_EC_inh, G_CA1_exc, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_22' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 260, in prepare_network\n",
      "    testing_S_EC_CA1_i2i_no_dist = Synapses(G_EC_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n",
      "WARNING    The object 'synapses_23' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
      "The object was created here (most recent call only):\n",
      "  File 'C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19864\\856984257.py', line 261, in prepare_network\n",
      "    testing_S_EC_CA1_i2i_dist = Synapses(G_EC_inh, G_CA1_inh, on_pre=\"hi_post+=\"+str(gain)+\"*\"+str(g_max_i/siemens)+\"*siemens\") [brian2.core.base.unused_brian_object]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bb338fdf0e4005aea549283d404346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Simulation:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    'glu' is an internal variable of group 'exc_group_CA1', but also exists in the run namespace with the value 1. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
      "WARNING    'glu' is an internal variable of group 'exc_group_DG_CA3', but also exists in the run namespace with the value 1. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
      "WARNING    'glu' is an internal variable of group 'exc_group_EC', but also exists in the run namespace with the value 1. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
      "WARNING    'glu' is an internal variable of group 'exc_group_Sub', but also exists in the run namespace with the value 1. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Running the simulation with the variables.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mrun_model_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 176\u001b[0m, in \u001b[0;36mrun_model_loop\u001b[1;34m(variables)\u001b[0m\n\u001b[0;32m    170\u001b[0m popmon_DG_CA3_exc, popmon_CA1_exc, popmon_Sub_exc, popmon_EC_exc, popmon_DG_CA3_inh, popmon_CA1_inh, popmon_Sub_inh, popmon_EC_inh, Mlfp, statemon_DG_CA3_exc, statemon_CA1_exc, statemon_Sub_exc, statemon_EC_exc, statemon_DG_CA3_inh, statemon_CA1_inh, statemon_Sub_inh, statemon_EC_inh \u001b[38;5;241m=\u001b[39m monitors\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Writing the network statistics to a file.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m#write_network_statistics(synapses, current_variables['N'], run_id)\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Running the simulation with the dynamic objects created above.\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[43mrun_granular_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreatment_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m###########################################\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m########  Saving Firing Rate Data  ########\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m###########################################\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Saving the firing rate data for every single region.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/firing_rate_DG_CA3_exc.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, popmon_DG_CA3_exc\u001b[38;5;241m.\u001b[39mrate)\n",
      "Cell \u001b[1;32mIn[18], line 36\u001b[0m, in \u001b[0;36mrun_granular_simulation\u001b[1;34m(net, variables, treatment_settings, monitors)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# For every batch, we run the simulation on the network 'net'. Here the 'tqdm()' function is used which creates a progress bar.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_batches), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n\u001b[1;32m---> 36\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_fragment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# If after running a time fragment, the average firing rate of the excitatory neurons over the last time fragment exceeds the threshold, treatment is initiated.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# This statement refers to the scenario where epilepsy is detected and treated by adjusting the potassium equilibrium potentials of the excitatory and inhibitory neurons.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(population_monitor\u001b[38;5;241m.\u001b[39mrate[\u001b[38;5;241m-\u001b[39mtime_fragment_ms:]) \u001b[38;5;241m>\u001b[39m firing_rate_threshold:\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\core\\base.py:346\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\units\\fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m             )\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(\n\u001b[0;32m   2649\u001b[0m                 error_message, get_dimensions(newkeyset[k])\n\u001b[0;32m   2650\u001b[0m             )\n\u001b[1;32m-> 2652\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m], Callable) \u001b[38;5;129;01mand\u001b[39;00m au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m   2657\u001b[0m     ):\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\core\\network.py:1141\u001b[0m, in \u001b[0;36mNetwork.run\u001b[1;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m get_local_namespace(level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m-> 1141\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_objects) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# TODO: raise an error? warning?\u001b[39;00m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\core\\base.py:346\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\core\\network.py:1003\u001b[0m, in \u001b[0;36mNetwork.before_run\u001b[1;34m(self, run_namespace)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mactive:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1003\u001b[0m         \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   1005\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrianObjectException(\n\u001b[0;32m   1006\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred when preparing an object.\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj\n\u001b[0;32m   1007\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\core\\base.py:346\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\synapses\\synapses.py:366\u001b[0m, in \u001b[0;36mSynapticPathway.before_run\u001b[1;34m(self, run_namespace)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;129m@device_override\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynaptic_pathway_before_run\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_namespace):\n\u001b[1;32m--> 366\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\groups\\group.py:1266\u001b[0m, in \u001b[0;36mCodeRunner.before_run\u001b[1;34m(self, run_namespace)\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_namespace):\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_code_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbefore_run(run_namespace)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\synapses\\synapses.py:394\u001b[0m, in \u001b[0;36mSynapticPathway.create_code_objects\u001b[1;34m(self, run_namespace)\u001b[0m\n\u001b[0;32m    380\u001b[0m     needed_variables \u001b[38;5;241m=\u001b[39m [eventspace_name]\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pushspikes_codeobj \u001b[38;5;241m=\u001b[39m create_runner_codeobj(\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# no code\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         run_namespace\u001b[38;5;241m=\u001b[39mrun_namespace,\n\u001b[0;32m    391\u001b[0m     )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_objects[:] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    393\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mproxy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pushspikes_codeobj),\n\u001b[1;32m--> 394\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mproxy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_default_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[0;32m    395\u001b[0m ]\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\groups\\group.py:1240\u001b[0m, in \u001b[0;36mCodeRunner.create_default_code_object\u001b[1;34m(self, run_namespace)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodeobj \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_runner_codeobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabstract_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemplate_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_codeobject*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneeded_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneeded_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_namespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemplate_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_conditional_write\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_conditional_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcodeobj_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodeobj_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodeobj\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\codegen\\codeobject.py:380\u001b[0m, in \u001b[0;36mcreate_runner_codeobj\u001b[1;34m(group, code, template_name, run_namespace, user_code, variable_indices, name, check_units, needed_variables, additional_variables, template_kwds, override_conditional_write, codeobj_class)\u001b[0m\n\u001b[0;32m    378\u001b[0m     _, uk, u \u001b[38;5;241m=\u001b[39m analyse_identifiers(v, all_variables, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    379\u001b[0m     identifiers \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m uk \u001b[38;5;241m|\u001b[39m u\n\u001b[1;32m--> 380\u001b[0m     _, uk, u \u001b[38;5;241m=\u001b[39m \u001b[43manalyse_identifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     user_identifiers \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m uk \u001b[38;5;241m|\u001b[39m u\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Add variables that are not in the abstract code, nor specified in the\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# template but nevertheless necessary\u001b[39;00m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\codegen\\translation.py:97\u001b[0m, in \u001b[0;36manalyse_identifiers\u001b[1;34m(code, variables, recursive)\u001b[0m\n\u001b[0;32m     94\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {k: Variable(name\u001b[38;5;241m=\u001b[39mk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m known}\n\u001b[0;32m     96\u001b[0m known \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m STANDARD_IDENTIFIERS\n\u001b[1;32m---> 97\u001b[0m scalar_stmts, vector_stmts \u001b[38;5;241m=\u001b[39m \u001b[43mmake_statements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m stmts \u001b[38;5;241m=\u001b[39m scalar_stmts \u001b[38;5;241m+\u001b[39m vector_stmts\n\u001b[0;32m    101\u001b[0m defined \u001b[38;5;241m=\u001b[39m {stmt\u001b[38;5;241m.\u001b[39mvar \u001b[38;5;28;01mfor\u001b[39;00m stmt \u001b[38;5;129;01min\u001b[39;00m stmts \u001b[38;5;28;01mif\u001b[39;00m stmt\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:=\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:93\u001b[0m, in \u001b[0;36mcached.<locals>.cached_func\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m         cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m---> 93\u001b[0m             [\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;241m+\u001b[39m [(key, _hashable(value)) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(kwds\u001b[38;5;241m.\u001b[39mitems())]\n\u001b[0;32m     95\u001b[0m         )\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;66;03m# If we cannot handle a type here, that most likely means that the\u001b[39;00m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;66;03m# user provided an argument of a type we don't handle. This will\u001b[39;00m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# lead to an error message later that is most likely more meaningful\u001b[39;00m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;66;03m# to the user than an error message by the caching system\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;66;03m# complaining about an unsupported type.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:130\u001b[0m, in \u001b[0;36m_hashable\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    128\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _of_type(obj_type, Mapping):\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfrozenset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:131\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    128\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _of_type(obj_type, Mapping):\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[1;32m--> 131\u001b[0m         (_hashable(key), \u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:127\u001b[0m, in \u001b[0;36m_hashable\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to make a few data structures hashable (e.g. a\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mdictionary gets converted to a frozenset). The function is specifically\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mtailored to our use case and not meant to be generally useful.\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_state_tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _of_type(obj_type, Mapping):\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:136\u001b[0m, in \u001b[0;36m_hashable\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Scalar Quantity object\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(obj), obj\u001b[38;5;241m.\u001b[39mdim\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:136\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Scalar Quantity object\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(obj), obj\u001b[38;5;241m.\u001b[39mdim\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\laure\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\brian2\\utils\\caching.py:137\u001b[0m, in \u001b[0;36m_hashable\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Scalar Quantity object\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(obj), obj\u001b[38;5;241m.\u001b[39mdim\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Running the simulation with the variables.\n",
    "run_model_loop(variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
